import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,a as e,o as n}from"./app-BiQR_lPj.js";const l={};function t(r,s){return n(),i("div",null,s[0]||(s[0]=[e(`<h1 id="腾讯开源基于大模型的智能知识库-轻松部署全攻略" tabindex="-1"><a class="header-anchor" href="#腾讯开源基于大模型的智能知识库-轻松部署全攻略"><span>腾讯开源基于大模型的智能知识库，轻松部署全攻略</span></a></h1><h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h2><p>在企业知识管理、科研文献分析、技术支持、法律合规审查等场景中，传统的全文检索和关键词匹配已经无法满足复杂、多模态的文档理解需求。</p><p>腾讯近期开源的 <strong>WeKnora</strong> 框架，将大语言模型（LLM）与语义检索、智能推理深度融合，为结构复杂、内容异构的文档提供高质量的问答与分析能力。</p><p>本文将带你快速了解 WeKnora 的核心特性，并手把手演示如何在 <strong>飞牛 NAS</strong> 上通过 Docker 部署，让你的私有知识库秒变“智能问答专家”。</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757256221891.png?tx" alt="img"></p><h2 id="weknora-项目介绍" tabindex="-1"><a class="header-anchor" href="#weknora-项目介绍"><span>WeKnora 项目介绍</span></a></h2><p>WeKnora（维娜拉） 是一款基于大语言模型（LLM）的文档理解与语义检索框架，专为结构复杂、内容异构的文档场景而打造。</p><p>框架采用模块化架构，融合多模态预处理、语义向量索引、智能召回与大模型生成推理，构建起高效、可控的文档问答流程。核心检索流程基于 RAG（Retrieval-Augmented Generation） 机制，将上下文相关片段与语言模型结合，实现更高质量的语义回答。</p><p>官网： https://weknora.weixin.qq.com</p><h2 id="核心特性" tabindex="-1"><a class="header-anchor" href="#核心特性"><span>核心特性</span></a></h2><ul><li><strong>🔍 精准理解</strong>：支持 PDF、Word、图片等文档的结构化内容提取，统一构建语义视图</li><li><strong>🧠 智能推理</strong>：借助大语言模型理解文档上下文与用户意图，支持精准问答与多轮对话</li><li><strong>🔧 灵活扩展</strong>：从解析、嵌入、召回到生成全流程解耦，便于灵活集成与定制扩展</li><li><strong>⚡ 高效检索</strong>：混合多种检索策略：关键词、向量、知识图谱</li><li><strong>🎯 简单易用</strong>：直观的Web界面与标准API，零技术门槛快速上手</li><li><strong>🔒 安全可控</strong>：支持本地化与私有云部署，数据完全自主可控</li></ul><h2 id="使用场景" tabindex="-1"><a class="header-anchor" href="#使用场景"><span>使用场景</span></a></h2><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757254553072.png?tx" alt="img"></p><h2 id="功能模块能力" tabindex="-1"><a class="header-anchor" href="#功能模块能力"><span>功能模块能力</span></a></h2><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757254588806.png?tx" alt="img"></p><h2 id="在飞牛-nas-上部署-weknora" tabindex="-1"><a class="header-anchor" href="#在飞牛-nas-上部署-weknora"><span>在飞牛 NAS 上部署 WeKnora</span></a></h2><blockquote><p>理论上，任何支持 Docker 的设备都可部署 WeKnora，这里以飞牛 NAS 为例。</p></blockquote><p>确保本地已安装以下工具：</p><p>Docker、Docker Compose、Git</p><h3 id="_1-启用-ssh-登录" tabindex="-1"><a class="header-anchor" href="#_1-启用-ssh-登录"><span>1. 启用 SSH 登录</span></a></h3><p>在飞牛 OS 中开启 <strong>SSH 登录</strong> 功能，并切换到 <code>root</code> 用户：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -i</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_2-创建部署目录" tabindex="-1"><a class="header-anchor" href="#_2-创建部署目录"><span>2. 创建部署目录</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">mkdir</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /data/docker</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &amp;&amp; </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /data/docker</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_3-克隆项目" tabindex="-1"><a class="header-anchor" href="#_3-克隆项目"><span>3. 克隆项目</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 克隆主仓库</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/Tencent/WeKnora.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> WeKnora</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-配置环境变量" tabindex="-1"><a class="header-anchor" href="#_4-配置环境变量"><span>4. 配置环境变量</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cp</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env.example</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 编辑 .env 填写对应配置信息</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p><code>.env.example</code> 文件中有详细注释，可根据实际情况修改。</p></blockquote><h3 id="_5-启动服务" tabindex="-1"><a class="header-anchor" href="#_5-启动服务"><span>5.启动服务</span></a></h3><p>如果需要安装ollama则执行这个，我这边不执行，因为我已经有安装ollama了。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span># 启动全部服务（含 Ollama 与后端容器）</span></span>
<span class="line"><span>./scripts/start_all.sh</span></span>
<span class="line"><span># 或</span></span>
<span class="line"><span>make start-all</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-启动服务备选" tabindex="-1"><a class="header-anchor" href="#_5-启动服务备选"><span>5.启动服务备选</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span># 启动服务</span></span>
<span class="line"><span>docker compose up -d</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757255116788.png?tx" alt="img"></p><p>接下来就看网络的情况了。</p><h3 id="_6-停止服务" tabindex="-1"><a class="header-anchor" href="#_6-停止服务"><span>6.停止服务</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>./scripts/start_all.sh --stop</span></span>
<span class="line"><span># 或</span></span>
<span class="line"><span>make stop-all</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="服务访问地址" tabindex="-1"><a class="header-anchor" href="#服务访问地址"><span>服务访问地址</span></a></h3><p>启动成功后，可访问以下地址：</p><ul><li>Web UI：<code>http://localhost</code></li><li>后端 API：<code>http://localhost:8080</code></li><li>链路追踪（Jaeger）：<code>http://localhost:16686</code></li></ul><p>首次进入需配置：</p><p>首次访问会自动跳转到初始化配置页面，配置完成后会自动跳转到知识库页面。请按照页面提示信息完成模型的配置。</p><ul><li>大模型（本地 ollama 或远程 API）</li><li>Embedding 模型</li><li>Rerank 模型</li><li>多模态解析</li><li>文档分割策略</li></ul><hr><h2 id="使用体验" tabindex="-1"><a class="header-anchor" href="#使用体验"><span>使用体验</span></a></h2><ol><li><strong>上传文档</strong><br> 支持批量上传，系统会自动解析并生成知识库索引。</li><li><strong>智能问答</strong><br> 输入问题，WeKnora 会结合知识库内容进行精准回答，并给出引用来源。</li><li><strong>多轮对话</strong><br> 支持上下文关联的连续提问，适合深度分析与探索。</li></ol><p>WeKnora 提供了一系列 RESTful API，用于创建和管理知识库、检索知识，以及进行基于知识的问答。本文档详细描述了这些 API 的使用方式。</p><h2 id="如何查看日志" tabindex="-1"><a class="header-anchor" href="#如何查看日志"><span>如何查看日志？</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span># 查看 主服务 日志</span></span>
<span class="line"><span>docker exec -it WeKnora-app tail -f /var/log/WeKnora.log</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 查看 文档解析模块 日志</span></span>
<span class="line"><span>docker exec -it WeKnora-docreader tail -f /var/log/docreader.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="如何启动和停止服务" tabindex="-1"><a class="header-anchor" href="#如何启动和停止服务"><span>如何启动和停止服务？</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span># 启动服务</span></span>
<span class="line"><span>./scripts/start_all.sh</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 停止服务</span></span>
<span class="line"><span>./scripts/start_all.sh --stop</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 清空数据库</span></span>
<span class="line"><span>./scripts/start_all.sh --stop &amp;&amp; make clean-db</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="应用场景" tabindex="-1"><a class="header-anchor" href="#应用场景"><span>应用场景</span></a></h2><ul><li>企业内部知识管理</li><li>科研文献分析</li><li>产品技术支持</li><li>法律合规审查</li><li>医疗知识辅助</li></ul><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>WeKnora 作为腾讯开源的 <strong>智能知识库框架</strong>，在文档解析、语义检索、智能推理等方面表现出色。 结合飞牛 NAS（其他的服务器也可以） 的本地化部署能力，你可以轻松构建一个 <strong>安全可控、功能强大</strong> 的私有知识库系统。</p><p>如果你正在寻找一款 <strong>可本地部署、支持多模态、基于大模型的知识库解决方案</strong>，WeKnora 值得一试。</p><p>写文不易，如果你都看到了这里，请点个赞和在看，分享给更多的朋友；也别忘了关注星哥玩云！这里有满满的干货分享，还有轻松有趣的技术交流～点个赞、分享给身边的小伙伴，一起成长，一起玩转技术世界吧！ 😊</p><h1 id="weknora的使用" tabindex="-1"><a class="header-anchor" href="#weknora的使用"><span>WeKnora的使用</span></a></h1><h2 id="_80端口被占用" tabindex="-1"><a class="header-anchor" href="#_80端口被占用"><span>80端口被占用</span></a></h2><p>由于搭建WeKnora的80端口被占用，报错：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>Error response from daemon: failed to set up container networking: driver failed programming external connectivity on endpoint WeKnora-frontend (6f1a34f78e900c8027c65236eaffc48c5d47611b979d6825797348b189559c37): failed to bind host port for 0.0.0.0:80:172.18.0.8:80/tcp: address already in use</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>修改 docker-compose.yml 文件</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>  frontend:</span></span>
<span class="line"><span>    image: wechatopenai/weknora-ui:latest</span></span>
<span class="line"><span>    container_name: WeKnora-frontend</span></span>
<span class="line"><span>    ports:</span></span>
<span class="line"><span>      - &quot;80:80&quot;  </span></span>
<span class="line"><span>中的 ‘80:80’改成 81:80</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>修改.env</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>vi .env</span></span>
<span class="line"><span>把OLLAMA_BASE_URL=http://host.docker.internal:11434</span></span>
<span class="line"><span>#OLLAMA_BASE_URL=http://host.docker.internal:11434</span></span>
<span class="line"><span>改成了</span></span>
<span class="line"><span>OLLAMA_BASE_URL=http://192.168.1.18:11434</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>再次运行</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker ps</span></span>
<span class="line"><span>CONTAINER ID   IMAGE                                   COMMAND                  CREATED          STATUS                   PORTS                                                                                                                                                                                              NAMES</span></span>
<span class="line"><span>7fe245b1547f   wechatopenai/weknora-ui:latest          &quot;/docker-entrypoint.…&quot;   32 minutes ago   Up 8 minutes             0.0.0.0:81-&gt;80/tcp                                                                                                                                                                                 WeKnora-frontend</span></span>
<span class="line"><span>02007c0d740a   wechatopenai/weknora-app:latest         &quot;supervisord -c /etc…&quot;   32 minutes ago   Up 8 minutes             0.0.0.0:8080-&gt;8080/tcp                                                                                                                                                                             WeKnora-app</span></span>
<span class="line"><span>49db9309840d   wechatopenai/weknora-docreader:latest   &quot;supervisord -c /etc…&quot;   32 minutes ago   Up 8 minutes             0.0.0.0:50051-&gt;50051/tcp                                                                                                                                                                           WeKnora-docreader</span></span>
<span class="line"><span>ea4ea9bf515f   jaegertracing/all-in-one:latest         &quot;/go/bin/all-in-one-…&quot;   32 minutes ago   Up 8 minutes             0.0.0.0:4317-4318-&gt;4317-4318/tcp, 0.0.0.0:5778-&gt;5778/tcp, 0.0.0.0:9411-&gt;9411/tcp, 0.0.0.0:14250-&gt;14250/tcp, 0.0.0.0:14268-&gt;14268/tcp, 0.0.0.0:16686-&gt;16686/tcp, 0.0.0.0:6831-6832-&gt;6831-6832/udp   weknora-jaeger-1</span></span>
<span class="line"><span>2f405f897e38   paradedb/paradedb:latest                &quot;docker-entrypoint.s…&quot;   32 minutes ago   Up 8 minutes (healthy)   0.0.0.0:5432-&gt;5432/tcp                                                                                                                                                                             WeKnora-postgres</span></span>
<span class="line"><span>eb7a460e95af   redis:7.0-alpine                        &quot;docker-entrypoint.s…&quot;   32 minutes ago   Up 8 minutes             0.0.0.0:6379-&gt;6379/tcp                                                                                                                                                                             WeKnora-redis</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="weknora-系统初始化配置" tabindex="-1"><a class="header-anchor" href="#weknora-系统初始化配置"><span>WeKnora 系统初始化配置</span></a></h2><p>由于局域网里面有安装ollama，所以安装WeKnora的时候就没有安装ollama。</p><h3 id="llm-大语言模型配置" tabindex="-1"><a class="header-anchor" href="#llm-大语言模型配置"><span>LLM 大语言模型配置</span></a></h3><p>模型名称： 使用 ollama list 查看有哪些模型，我这里使用 gpt-oss:20b</p><p>Base URL填写： <code>http://192.168.1.18:11434/v1</code></p><p>测试：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>curl http://192.168.1.18:11434/api/generate -d &#39;{</span></span>
<span class="line"><span>  &quot;model&quot;: &quot;gpt-oss:20b&quot;,</span></span>
<span class="line"><span>  &quot;prompt&quot;: &quot;Why is the sky blue?&quot;,</span></span>
<span class="line"><span>  &quot;stream&quot;: false </span></span>
<span class="line"><span>}&#39;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="embedding-嵌入模型配置" tabindex="-1"><a class="header-anchor" href="#embedding-嵌入模型配置"><span>Embedding 嵌入模型配置</span></a></h3><p>模型名称：nomic-embed-text:latest （没有则需要安装）</p><p>维度：768（维度必须为有效整数值，常见取值为768, 1024, 1536, 3584等）</p><p>Base URL填写： <code>http://192.168.1.18:11434/v1</code></p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757301490702.png?tx" alt="img"></p><h2 id="完成配置" tabindex="-1"><a class="header-anchor" href="#完成配置"><span>完成配置</span></a></h2><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757301881161.png?tx" alt="img"></p><p>上传文章</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757302299670.png?tx" alt="img"></p><p>再问个问题</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1757302426203.png?tx" alt="img"></p>`,87)]))}const h=a(l,[["render",t]]),c=JSON.parse('{"path":"/kaiyuan2025/%E8%85%BE%E8%AE%AF%E5%BC%80%E6%BA%90WeKnora.html","title":"腾讯开源基于大模型的智能知识库，轻松部署全攻略","lang":"en-US","frontmatter":{},"git":{"createdTime":1760001321000,"updatedTime":1760001321000,"contributors":[{"name":"star","username":"star","email":"star@xgss.net","commits":1,"url":"https://github.com/star"}]},"readingTime":{"minutes":5.81,"words":1744},"filePathRelative":"kaiyuan2025/腾讯开源WeKnora.md"}');export{h as comp,c as data};
