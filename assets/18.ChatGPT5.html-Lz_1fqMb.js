import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as p,a as n,o as e}from"./app-BiQR_lPj.js";const i={};function t(l,s){return e(),p("div",null,s[0]||(s[0]=[n(`<h1 id="openai发布最新大模型gpt5、本地部署gpt开源模型" tabindex="-1"><a class="header-anchor" href="#openai发布最新大模型gpt5、本地部署gpt开源模型"><span>OpenAI发布最新大模型GPT5、本地部署GPT开源模型</span></a></h1><h2 id="gpt-5概述" tabindex="-1"><a class="header-anchor" href="#gpt-5概述"><span>GPT-5概述</span></a></h2><p>北京时间 2025年8月8日 凌晨1点 OPENAI举行了1个小时的线上发布会，正式推出了其史上最聪明、最强大的大模型GPT-5。</p><p>GPT-5是OpenAI发布的最新一代大型语言模型，它基于Transformer架构，经过大规模的文本数据训练，能够生成流畅、自然的语言输出。与前几代相比，GPT-5的技术进步体现在其更强大的理解能力、更准确的推理能力以及更高效的对话表现。</p><p>GPT-5具备以下几个显著特点：</p><p><strong>更大的参数规模</strong>：GPT-5拥有比GPT-4更多的参数，使其能够处理更为复杂的语言任务。</p><p><strong>多模态能力</strong>：除了文本输入输出，GPT-5还支持图像、音频等多种数据类型的处理，能够进行跨媒体的内容生成。</p><p><strong>增强的推理能力</strong>：在自然语言推理、抽象思维以及复杂问题解决方面，GPT-5表现得更为出色，能够处理更具挑战性的任务。</p><p><strong>更加个性化的对话</strong>：GPT-5能够根据用户的需求提供更加个性化和具体的答案，甚至具备更灵活的情感反馈能力。</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1755001990336.png?tx" alt="img"></p><h2 id="如何使用gpt5" tabindex="-1"><a class="header-anchor" href="#如何使用gpt5"><span>如何使用GPT5</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>GPT5的中文介绍： https://openai.com/zh-Hans-CN/index/introducing-gpt-oss/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol><li>访问ChatGPT官网，免费用户每日有次数的限额、使用钞能力。</li><li>使用微软的copilot可以免登录使用GPT5、但是需要一些魔法。</li></ol><h2 id="开源模型-gpt-oss-20b-与-gpt-oss-120b" tabindex="-1"><a class="header-anchor" href="#开源模型-gpt-oss-20b-与-gpt-oss-120b"><span>开源模型 gpt-oss-20b 与 gpt-oss-120b</span></a></h2><p>OpenAI 开源 gpt-oss-20b 与 gpt-oss-120b 两款模型，Apache 2.0 许可证，水平与 o4-mini 相当，MoE 架构，带有思维链，可微调，本地 Agent 函数调用等功能，原生 MXFP4 量化，120b可以跑在高端笔记本或者单块 H100 上，20b版本可以跑在手机上。</p><h3 id="gpt-oss-120b" tabindex="-1"><a class="header-anchor" href="#gpt-oss-120b"><span>GPT-oss-120b</span></a></h3><p>GPT-oss-120b 模型在核心推理基准测试中与 OpenAI o4-mini 模型几乎持平，同时能在单个 80GB GPU 上高效运行。</p><h3 id="gpt-oss-20b" tabindex="-1"><a class="header-anchor" href="#gpt-oss-20b"><span>Gpt-oss-20b</span></a></h3><p>Gpt-oss-20b 模型在常见基准测试中与 OpenAI o3‑mini 模型取得类似结果，且可在仅配备 16GB 内存的边缘设备上运行，使其成为设备端应用、本地推理或无需昂贵基础设施的快速迭代的理想选择。</p><p>这两个模型在工具使用、少样本函数调用、CoT推理（如在 Tau-Bench 智能体评估套件中的结果所示）以及 HealthBench 测试中表现强劲（甚至超越了 OpenAI o1 和 GPT‑4o 等专有模型）。</p><h2 id="gpt-oss-20b-与-gpt-oss-120b-最低硬件要求" tabindex="-1"><a class="header-anchor" href="#gpt-oss-20b-与-gpt-oss-120b-最低硬件要求"><span>gpt-oss-20b 与 gpt-oss-120b 最低硬件要求</span></a></h2><p>来自ChatGPT5的回答</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1755000824661.png?tx" alt="img"></p><p>来自本地gpt-oss-20b的回答</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1755000868416.png?tx" alt="img"></p><h2 id="如何在本地安装开源的gpt-oss-20b" tabindex="-1"><a class="header-anchor" href="#如何在本地安装开源的gpt-oss-20b"><span>如何在本地安装开源的GPT-oss-20b</span></a></h2><p>星哥的测试环境</p><p>系统：Windows11专业版</p><p>CPU: 英特尔I7-13700KF</p><p>内存： 32G</p><p>硬盘：1T nvme +4T HHD</p><p>显卡：RTX 4070 Ti （12G）</p><h2 id="安装最新版的-ollama" tabindex="-1"><a class="header-anchor" href="#安装最新版的-ollama"><span>安装最新版的 Ollama</span></a></h2><p>去到ollama官网下载系统对应的软件，我这里下载window版本的。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span> ollama 的官方下载地址。 https://ollama.com/download</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1755001083912.png?tx" alt="img"></p><p>再到 命令行中powershell使用</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run gpt-oss </span></span>
<span class="line"><span>ollama run gpt-oss:20b</span></span>
<span class="line"><span>根据不同的网络状况需要的时间不同。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>PS C:\\Users\\Administrator&gt; ollama list | Select-String &quot;gpt&quot;</span></span>
<span class="line"><span>gpt-oss:20b                f2b8351c629c    13 GB     5 days ago</span></span>
<span class="line"><span>https://ollama.com/library/gpt-oss</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1755001200851.png?tx" alt="img"></p><h2 id="在-ollama上使用gpt-oss-20b" tabindex="-1"><a class="header-anchor" href="#在-ollama上使用gpt-oss-20b"><span>在 Ollama上使用gpt-oss:20b</span></a></h2><p>ollama安装完成之后，可以打开ollama界面，如图。</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1755001283509.png?tx" alt="img"></p><h2 id="ollama的turbo服务" tabindex="-1"><a class="header-anchor" href="#ollama的turbo服务"><span>Ollama的Turbo服务</span></a></h2><p>Ollama 推出了名为 “Turbo” 的付费服务，旨在解决本地运行超大模型的性能瓶颈，让用户在数据中心级的硬件上运行大型开源模型，服务月费为 20 美元。</p><p>Ollama “Turbo” 适用场景：</p><p>本地显卡显存不足，无法加载 120B 级别模型，需要快速原型验证、批量推理或高并发调用</p><p>希望保持本地环境简洁，同时获得接近数据中心的性能</p><p>据介绍，Ollama “Turbo” 服务主要解决新模型体积过大、在普通 GPU 上难以运行或运行缓慢的问题。通过将模型运行负载转移到云端，用户可以释放本地计算机（Mac, Windows, Linux）的性能。在预览阶段，Turbo 支持 gpt-oss-20b 和 gpt-oss-120b 模型。</p><h2 id="最后" tabindex="-1"><a class="header-anchor" href="#最后"><span>最后</span></a></h2><p>以上就是全部内容，GPT-5的简介和在本地搭建使用OpenAI的GPT-oss的开源模型。</p><p>写文不易，如果你都看到了这里，请点个赞和在看，分享给更多的朋友；也别忘了关注星哥玩云！这里有满满的干货分享，还有轻松有趣的技术交流～点个赞、分享给身边的小伙伴，一起成长，一起玩转技术世界吧！ 😊</p>`,51)]))}const h=a(i,[["render",t]]),g=JSON.parse('{"path":"/chatgpt2025/18.ChatGPT5.html","title":"OpenAI发布最新大模型GPT5、本地部署GPT开源模型","lang":"en-US","frontmatter":{},"git":{"createdTime":1755655357000,"updatedTime":1755655357000,"contributors":[{"name":"star","username":"star","email":"star@xgss.net","commits":1,"url":"https://github.com/star"}]},"readingTime":{"minutes":4.1,"words":1229},"filePathRelative":"chatgpt2025/18.ChatGPT5.md"}');export{h as comp,g as data};
