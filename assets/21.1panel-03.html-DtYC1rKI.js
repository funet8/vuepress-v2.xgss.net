import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as n,o as i}from"./app-BiQR_lPj.js";const l={};function p(t,a){return i(),e("div",null,a[0]||(a[0]=[n(`<h1 id="使用1panel面板搭建属于你的ai项目环境" tabindex="-1"><a class="header-anchor" href="#使用1panel面板搭建属于你的ai项目环境"><span>使用1Panel面板搭建属于你的AI项目环境</span></a></h1><p>在 AI 项目越来越火的今天，很多朋友都想自己动手搭建一个属于自己的实验环境。但问题来了：环境配置复杂、命令行操作繁琐、依赖冲突频发……这些“劝退三连”让不少人望而却步。</p><p>别担心，今天星哥就带你用 <strong>1Panel 面板</strong>，轻松搞定 AI 项目的运行环境，让你把精力更多放在模型和代码上，而不是环境折腾上。</p><p>环境搭建请参考之前的文章：</p><p><a href="https://mp.weixin.qq.com/s/QYu3nISGOAr1wL1Mhl85Yw" target="_blank" rel="noopener noreferrer">云服务器部署服务器面板1Panel：小白轻松构建Web服务与面板加固指南</a></p><p><a href="https://mp.weixin.qq.com/s/Ai61bwhE_bg-gL3KL7yZmw" target="_blank" rel="noopener noreferrer">开源神器组合！1Panel面板+Halo助你轻松打造个人/企业内容中心</a></p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760693146391.png?tx" alt="img"></p><h2 id="安装ollama" tabindex="-1"><a class="header-anchor" href="#安装ollama"><span>安装Ollama</span></a></h2><p>登录1Panel，应用商店，AI</p><p>找到Ollama,点击安装</p><p>这里要配置外网访问。</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760603549670.png?tx" alt="img"></p><p>安装ollama</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760603630136.png?tx" alt="img"></p><p>ollama 安装完成</p><h2 id="安装deepseek" tabindex="-1"><a class="header-anchor" href="#安装deepseek"><span>安装deepseek</span></a></h2><p>依次点“模型”，“添加模型”，填写模型名称</p><p>我这边服务器配置比较低，就填&quot;deepseek-r1:1.5b&quot;等一段时间的下载安装</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760685068431.png?tx" alt="img"></p><p>另一种安装方式就是进终端安装，最终效果一样。</p><p>进入 容器 列表，找到 Ollama 容器，点击进入终端运行并与 DeepSeek R1 聊天：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run deepseek-r1:1.5b</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>注意：您应该至少有 8 GB 可用 RAM 来运行 7B 型号，16 GB 来运行 13B 型号，32 GB 来运行 33B 型号。</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760604044564.png?tx" alt="img"></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker ps |grep ollama</span></span>
<span class="line"><span>CONTAINER ID   IMAGE                                 COMMAND                  CREATED         STATUS                  PORTS                                                  NAMES</span></span>
<span class="line"><span>4d9d955b10b7   ollama/ollama:0.12.5                  &quot;/bin/ollama serve&quot;      2 minutes ago   Up 2 minutes            127.0.0.1:11434-&gt;11434/tcp                             1Panel-ollama-dymw</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>进入容器安装模型</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span></span></span>
<span class="line"><span>[root@VM-12-4-centos ~]# docker exec -it 1Panel-ollama-dymw /bin/bash</span></span>
<span class="line"><span>root@4d9d955b10b7:/# ollama run deepseek-r1:1.5b</span></span>
<span class="line"><span>pulling manifest </span></span>
<span class="line"><span>pulling aabd4debf0c8:  23% ▕███████████████████████████████████████████                                                                                                                                                     ▏ 255 MB/1.1 GB   35 MB/s     24s</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Ollama 支持 <a href="https://ollama.com/library" target="_blank" rel="noopener noreferrer">ollama.com/library</a> 上提供的一系列模型</p><h3 id="deepseek-r1-1-5b安装成功" tabindex="-1"><a class="header-anchor" href="#deepseek-r1-1-5b安装成功"><span>deepseek-r1:1.5b安装成功</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>pulling manifest </span></span>
<span class="line"><span>pulling aabd4debf0c8: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 1.1 GB                         </span></span>
<span class="line"><span>pulling c5ad996bda6e: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  556 B                         </span></span>
<span class="line"><span>pulling 6e4c38e1172f: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 1.1 KB                         </span></span>
<span class="line"><span>pulling f4d24e9138dd: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  148 B                         </span></span>
<span class="line"><span>pulling a85fe2a2e58e: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  487 B                         </span></span>
<span class="line"><span>verifying sha256 digest </span></span>
<span class="line"><span>writing manifest </span></span>
<span class="line"><span>success </span></span>
<span class="line"><span>&gt;&gt;&gt; hello</span></span>
<span class="line"><span>Hello! How can I assist you today? 😊</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="安装maxkb" tabindex="-1"><a class="header-anchor" href="#安装maxkb"><span>安装MaxKB</span></a></h3><p>如图点击“应用商店”，AI，</p><p>安装MaxKB</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760685235023.png?tx" alt="img"></p><p><strong>MaxKB</strong> = Max Knowledge Brain，是一款强大易用的企业级智能体平台，支持 RAG 检索增强生成、工作流编排、MCP 工具调用能力。MaxKB 支持对接各种主流大语言模型，广泛应用于智能客服、企业内部知识库问答、员工助手、学术研究与教育等场景。</p><h3 id="maxkb优势" tabindex="-1"><a class="header-anchor" href="#maxkb优势"><span>MaxKB优势</span></a></h3><ul><li><strong>RAG 检索增强生成</strong>：高效搭建本地 AI 知识库，支持直接上传文档 / 自动爬取在线文档，支持文本自动拆分、向量化，有效减少大模型幻觉，提升问答效果；</li><li><strong>灵活编排</strong>：内置强大的工作流引擎、函数库和 MCP 工具调用能力，支持编排 AI 工作过程，满足复杂业务场景下的需求；</li><li><strong>无缝嵌入</strong>：支持零编码快速嵌入到第三方业务系统，让已有系统快速拥有智能问答能力，提高用户满意度；</li><li><strong>模型中立</strong>：支持对接各种大模型，包括本地私有大模型（DeepSeek R1 / Llama 3 / Qwen 2 等）、国内公共大模型（通义千问 / 腾讯混元 / 字节豆包 / 百度千帆 / 智谱 AI / Kimi 等）和国外公共大模型（OpenAI / Claude / Gemini 等）。</li></ul><h3 id="maxkb默认账户密码" tabindex="-1"><a class="header-anchor" href="#maxkb默认账户密码"><span>MaxKB默认账户密码</span></a></h3><p>用户名: <code>admin</code> 密码: <code>MaxKB@123..</code></p><p>由于服务器性能较低，开启maxkb之后，直接卡死了，重启服务器把容器给rm了。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker rm -f  1Panel-maxkb-Ep60</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="安装lobe-chat" tabindex="-1"><a class="header-anchor" href="#安装lobe-chat"><span>安装lobe-chat</span></a></h2><p>同样的方式安装lobe-chat</p><p>这里要配置访问密码，我这里填2017</p><p>打开“端口外部访问”（如果不打开，可以使用域名反向代理）。</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760685579448.png?tx" alt="img"></p><h2 id="访问lobe-chat" tabindex="-1"><a class="header-anchor" href="#访问lobe-chat"><span>访问lobe-chat</span></a></h2><p>使用IP+端口访问</p><p>输入刚才配置的访问密码</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760690004087.png?tx" alt="img"></p><h3 id="配置模型" tabindex="-1"><a class="header-anchor" href="#配置模型"><span>配置模型</span></a></h3><p>这里可以deepseek、ChatGPT、腾讯混元等等大模型。</p><p>我这里用本机的deepseek</p><p><img src="https://imgoss.xgss.net/picgo-tx2025/QQ_1760690300302.png?tx" alt="img"></p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>通过 1Panel，你可以在极短时间内完成 AI 项目环境的搭建：</p><ul><li>从服务器管理到应用部署，一切都在图形化界面中完成</li><li>支持多种 AI 模型（如 Ollama、DeepSeek-R1），灵活扩展</li><li>提供监控、告警、备份等功能，保障项目稳定运行</li></ul><p>如果你也想拥有一个属于自己的 AI 实验室，不妨试试用 1Panel 来搭建，相信会让你的探索之旅更加高效与顺畅。</p>`,58)]))}const c=s(l,[["render",p]]),h=JSON.parse('{"path":"/cloud/tengxun2025/21.1panel-03.html","title":"使用1Panel面板搭建属于你的AI项目环境","lang":"en-US","frontmatter":{},"git":{"createdTime":1761192011000,"updatedTime":1761192011000,"contributors":[{"name":"star","username":"star","email":"star@xgss.net","commits":1,"url":"https://github.com/star"}]},"readingTime":{"minutes":3.84,"words":1151},"filePathRelative":"cloud/tengxun2025/21.1panel-03.md"}');export{c as comp,h as data};
