import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as p,a as s,o as n}from"./app-BiQR_lPj.js";const i={};function t(h,a){return n(),p("div",null,a[0]||(a[0]=[s('<h1 id="【hai要玩ai】腾讯云高性能应用服务hai搭建开源大模型deepseek-anythingllm实现企业知识库" tabindex="-1"><a class="header-anchor" href="#【hai要玩ai】腾讯云高性能应用服务hai搭建开源大模型deepseek-anythingllm实现企业知识库"><span>【HAI要玩AI】腾讯云高性能应用服务HAI搭建开源大模型DeepSeek+AnythingLLM实现企业知识库</span></a></h1><h1 id="腾讯云高性能应用服务hai" tabindex="-1"><a class="header-anchor" href="#腾讯云高性能应用服务hai"><span>腾讯云高性能应用服务HAI</span></a></h1><p>高性能应用服务（Hyper Application Inventor，HAI）是一款面向 AI 、科学计算的 GPU 应用服务产品，提供即插即用的澎湃算力与常见环境，助力中小企业及开发者快速部署 LLM。</p><p>对于初步探索AIGC的用户，可以选择基础型算力套餐，以较低的成本进行尝试。腾讯云高性能应用服务HAI-CPU支持关机不计费，用户可以根据自身使用需求动态开关机，节省成本。此外，通过选择合适的算力套餐和购买时长，也可以进一步降低使用成本。</p><p>今天我们就来学习一下如何快速使用腾讯云高性能应用服务HAI搭建开源大模型DeepSeek+AnythingLLM实现企业知识库。</p><h2 id="_1元特惠" tabindex="-1"><a class="header-anchor" href="#_1元特惠"><span>1元特惠</span></a></h2><p>新老用户专享特惠，超值现金券活动火热进行中！基础型算力折后0.79元/时起。点击：https://cloud.tencent.com/act/pro/hai</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321115503911.png?aliyun" alt="image-20250321115503911"></p><p>点击购买，即可一元使用HAI</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321115600291.png?aliyun" alt="image-20250321115600291"></p><p>购买完了就可以抵扣8小时的GPU基础型算力。</p><h1 id="购买hai" tabindex="-1"><a class="header-anchor" href="#购买hai"><span>购买HAI</span></a></h1><h2 id="_1-应用选择" tabindex="-1"><a class="header-anchor" href="#_1-应用选择"><span>1.应用选择</span></a></h2><p>这里选择社区应用，deepseek-R1 AnythingLLM</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321141435398.png?aliyun" alt="image-20250321141435398"></p><h2 id="_2-计费模式" tabindex="-1"><a class="header-anchor" href="#_2-计费模式"><span>2.计费模式</span></a></h2><p>计费模式选择按量计费，适用需求量有大幅波动的场景，我这里选择按量计费</p><p>适用需求量长期稳定的业务</p><h2 id="_3-地域" tabindex="-1"><a class="header-anchor" href="#_3-地域"><span>3.地域</span></a></h2><p>地域我这里选择广州，可以根据实际情况来选择</p><h2 id="_4-算力方案" tabindex="-1"><a class="header-anchor" href="#_4-算力方案"><span>4.算力方案</span></a></h2><p>我这里选择GPU基础型</p><h2 id="_5-实例名称" tabindex="-1"><a class="header-anchor" href="#_5-实例名称"><span>5.实例名称</span></a></h2><p>随便取个名称即可，DeepSeek-r1</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321141700726.png?aliyun" alt="image-20250321141700726"></p><p>其他默认即可。</p><h2 id="_6-创建应用" tabindex="-1"><a class="header-anchor" href="#_6-创建应用"><span>6.创建应用</span></a></h2><p>实例创建中，这里等待几分钟成功之后，点击算力连接，再点击AnytingLLM</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321141839763.png?aliyun" alt="image-20250321141839763"></p><h1 id="连接deepseek" tabindex="-1"><a class="header-anchor" href="#连接deepseek"><span>连接deepseek</span></a></h1><p>点击AnytingLLM浏览器会弹出IP+端口进入AnythingLLM页面，如下图</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321142612300.png?aliyun" alt="image-20250321142612300"></p><h2 id="_1-配置llm首选项" tabindex="-1"><a class="header-anchor" href="#_1-配置llm首选项"><span>1.配置LLM首选项</span></a></h2><p>在浏览器左下角点击设置，再点击LLM首选项</p><p>将“LLM提供商”选择为“Ollama” 将“Ollama Base url”修改为：该台HAI实例的公网ip:6399，如 http://127.0.0.1（此步骤为最关键的一步） 在“Ollama Model”处选择需要使用的模型，如“deepseek-r1:32b” 在“Ollama keep alive”处按需配置保活时长，本最佳实践将其配置为永久。（模型在每次超过保活时长后会被移除，再次使用时需重新载入模型，耗时较久，若不存在频繁切换模型诉求，建议将保活时长尽可能调大）</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321143051678.png?aliyun" alt="image-20250321143051678"></p><h2 id="_2-新建工作区" tabindex="-1"><a class="header-anchor" href="#_2-新建工作区"><span>2.新建工作区</span></a></h2><p>在AnythingLLM左侧点击，新工作区，随便写一个工作区的名字</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321143143748.png?aliyun" alt="image-20250321143143748"></p><h2 id="_3-上传文件" tabindex="-1"><a class="header-anchor" href="#_3-上传文件"><span>3.上传文件</span></a></h2><p>配置完成后，回到项目页面，点击“upload a document”上传本地文件</p><p>把我们准备的工作文件“1.Ubuntu-初始化.md”等的文档上传上去</p><h2 id="_4-移动工作区" tabindex="-1"><a class="header-anchor" href="#_4-移动工作区"><span>4.移动工作区</span></a></h2><p>上传文件后，选中希望使用的文件，点击“move to workspace”将文件添加至项目。点击“save and embed”按钮，完成配置。</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321143932662.png?aliyun" alt="image-20250321143932662"></p><h2 id="_5-对话" tabindex="-1"><a class="header-anchor" href="#_5-对话"><span>5.对话</span></a></h2><p>您可直接与模型进行对话，模型会根据对话内容智能调用本地知识库内容。</p><p>本地知识库里面的“固定IP”</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321144803854.png?aliyun" alt="image-20250321144803854"></p><h1 id="最后" tabindex="-1"><a class="header-anchor" href="#最后"><span>最后</span></a></h1><h2 id="安全性" tabindex="-1"><a class="header-anchor" href="#安全性"><span>安全性</span></a></h2><p>由于deepseek和AnythingLLM没有配置密码，所以其他人只要知道IP+端口都可以使用，如果是长期项目</p><p><img src="https://imgoss.xgss.net/picgo/image-20250321144740428.png?aliyun" alt="image-20250321144740428"></p><h2 id="费用" tabindex="-1"><a class="header-anchor" href="#费用"><span>费用</span></a></h2><p>因为HAI涉及到腾讯云费用的问题，我的1元套餐可以使用8小时，8小时以后不再使用一定要记得销毁，而不是关机，关机还会收费的。</p>',55)]))}const c=e(i,[["render",t]]),d=JSON.parse('{"path":"/article/tmmmaxht/","title":"4.[HAI要玩AI]腾讯云高性能应用服务HAI搭建开源大模型DeepSeek，AnythingLLM实现企业知识库","lang":"en-US","frontmatter":{"title":"4.[HAI要玩AI]腾讯云高性能应用服务HAI搭建开源大模型DeepSeek，AnythingLLM实现企业知识库","createTime":"2025/05/27 17:51:17","permalink":"/article/tmmmaxht/"},"git":{"createdTime":1749111496000,"updatedTime":1750129445000,"contributors":[{"name":"star","username":"star","email":"star@xgss.net","commits":2,"url":"https://github.com/star"}]},"readingTime":{"minutes":3.42,"words":1027},"filePathRelative":"cloud/tengxun2025/4.[HAI要玩AI]腾讯云高性能应用服务HAI搭建开源大模型DeepSeek，AnythingLLM实现企业知识库.md"}');export{c as comp,d as data};
