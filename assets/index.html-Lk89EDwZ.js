import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,a as i,o as n}from"./app-BiQR_lPj.js";const l={};function p(t,a){return n(),s("div",null,a[0]||(a[0]=[i(`<h1 id="本机部署大语言模型ollama和openwebui实现各大模型的人工智能自由" tabindex="-1"><a class="header-anchor" href="#本机部署大语言模型ollama和openwebui实现各大模型的人工智能自由"><span>本机部署大语言模型Ollama和OpenWebUI实现各大模型的人工智能自由</span></a></h1><p>本篇文章介绍在window系统下，安装Ollama并且安装gemma（谷歌大模型）、llama2（脸书大模型）、qwen（阿里大模型）等大模型的教程，实现类似免费ChatGPT的web界面</p><p><img src="https://imgoss.xgss.net/picgo/OllamaFengmian.png?aliyun" alt="OllamaFengmian"></p><h2 id="安装之后的web界面" tabindex="-1"><a class="header-anchor" href="#安装之后的web界面"><span>安装之后的web界面</span></a></h2><p><img src="https://imgoss.xgss.net/picgo/image-20240514091912366.png?aliyun" alt="image-20240514091912366"></p><h1 id="什么是ollama" tabindex="-1"><a class="header-anchor" href="#什么是ollama"><span>什么是Ollama</span></a></h1><p>Ollama是一个开源项目，旨在让用户能够轻松地在其本地计算机上运行大型语言模型（LLM），是一个开源的大型语言模型服务。它支持各种LLM，包括Llama 3、Mistral和Gemma。</p><p>提供了类似OpenAI的API接口和聊天界面,可以非常方便地部署最新版本的GPT模型并通过接口使用。支持热加载模型文件,无需重新启动即可切换不同的模型。</p><p><img src="https://imgoss.xgss.net/picgo/ollama.png?aliyun" alt="img"></p><p>Ollama官网： https://ollama.com/</p><p>Ollama GitHub仓库：https://github.com/ollama/ollama</p><p>Ollama文档：https://github.com/ollama/ollama/blob/main/docs/api.md</p><h1 id="ollama的优势" tabindex="-1"><a class="header-anchor" href="#ollama的优势"><span>Ollama的优势</span></a></h1><p><strong>易用性:</strong></p><p>1.Ollama的API设计简洁明了，即使是初学者也可以轻松上手。 2.提供类似OpenAI的简单内容生成接口，极易上手使用。 3.类似ChatGPT的的聊天界面，无需开发直接与模型聊天。</p><p><strong>灵活性:</strong></p><p>1.支持多种LLM，如Llama 2、Code Llama、Mistral、Gemma 等，并允许用户根据特定需求定制和创建自己的模型。 2.支持热切换模型，灵活多变。</p><p><strong>可控性:</strong></p><p>1.可以本地运行LLM，因此用户可以完全控制自己的数据和隐私。 2.可定制模型参数、数据目录和其他设置。</p><p><strong>经济性:</strong></p><p>1.与使用云服务相比，本地运行LLM可以更省钱。</p><p><strong>离线能力:</strong></p><p>1.可让您离线运行LLM，这对于隐私和安全非常重要。</p><h1 id="安装ollama" tabindex="-1"><a class="header-anchor" href="#安装ollama"><span>安装Ollama</span></a></h1><p>本次安装环境为：Windows11，当然其他系统也可以支持。</p><h2 id="下载ollama" tabindex="-1"><a class="header-anchor" href="#下载ollama"><span>下载Ollama</span></a></h2><p>Ollama下载地址：https://ollama.com/download</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511151054662.png?aliyun" alt="image-20240511151054662"></p><h2 id="安装ollama-1" tabindex="-1"><a class="header-anchor" href="#安装ollama-1"><span>安装Ollama</span></a></h2><p>安装也比较方便，双击打开 install</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511151331009.png?aliyun" alt="image-20240511151331009"></p><p>安装完成没有提示，我们打开一个终端，本文以Windows PowerShell为例，大家也可以使用其他的：</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511151503523.png?aliyun" alt="image-20240511151503523"></p><p>现在Ollama已经安装完了，我们需要在终端中输入下方命令运行一个大语言模型进行测试，这里以对在中文方面表现相对好些的千问为例，大家也可以使用其他的模型。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run qwen</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo/image-20240511151819825.png?aliyun" alt="image-20240511151819825"></p><p>安装成功，随便问几个问题。</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511151923267.png?aliyun" alt="image-20240511151923267"></p><h2 id="修改路径" tabindex="-1"><a class="header-anchor" href="#修改路径"><span>修改路径</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>可以看到，系统正在下载qwen的模型（并保存在C盘，C:\\Users&lt;username&gt;.ollama\\models 如果想更改默认路径，可以通过设置OLLAMA_MODELS进行修改，然后重启终端，重启ollama服务。）</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>setx OLLAMA_MODELS &quot;D:\\ollama\\model&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h1 id="安装open-webui" tabindex="-1"><a class="header-anchor" href="#安装open-webui"><span>安装Open WebUI</span></a></h1><p>Open WebUI是一个用于在本地运行大型语言模型（LLM）的开源Web界面。</p><h2 id="在window下安装docker" tabindex="-1"><a class="header-anchor" href="#在window下安装docker"><span>在window下安装docker</span></a></h2><h3 id="_1-启动hyper-v" tabindex="-1"><a class="header-anchor" href="#_1-启动hyper-v"><span>1.启动Hyper-v</span></a></h3><p>打开控制面板，在程序与功能页面选择启用或Windows功能</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511153112805.png?aliyun" alt="image-20240511153112805"></p><p>然后，重启计算机。</p><h3 id="_2-安装wsl" tabindex="-1"><a class="header-anchor" href="#_2-安装wsl"><span>2.安装WSL</span></a></h3><p>打开 powershell，以管理员的身份启动命令窗口，输入</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>wsl --update</span></span>
<span class="line"><span></span></span>
<span class="line"><span>wsl --install</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果不是已管理员身份启动则会报错：请求的操作需要提升</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511154319596.png?aliyun" alt="image-20240511154319596"></p><p>然后再次重启电脑。</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511172942703.png?aliyun" alt="image-20240511172942703"></p><h3 id="_3-下载docker软件" tabindex="-1"><a class="header-anchor" href="#_3-下载docker软件"><span>3.下载Docker软件</span></a></h3><p>点击下载链接：https://docs.docker.com/desktop/install/windows-install/</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511153811506.png?aliyun" alt="image-20240511153811506"></p><h3 id="_4-安装docker" tabindex="-1"><a class="header-anchor" href="#_4-安装docker"><span>4.安装Docker</span></a></h3><p><img src="https://imgoss.xgss.net/picgo/image-20240511155742842.png?aliyun" alt="image-20240511155742842"></p><h2 id="使用docker部署open-webui" tabindex="-1"><a class="header-anchor" href="#使用docker部署open-webui"><span>使用Docker部署Open WebUI</span></a></h2><p>在Open WebUI的github页面 https://github.com/open-webui/open-webui</p><p>参考： https://docs.openwebui.com/getting-started/#quick-start-with-docker-</p><p>可以看到，如果你的Ollama和Open WebUI在同一台主机，那使用下面显示的这一行命令就可以在本地快速进行部署：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>现在我们打开终端，比如powershell，然后输入docker，回车</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511173724816.png?aliyun" alt="image-20240511173724816"></p><p>然后将上边在docker中部署Open WebUI的命令复制后粘贴到终端中，回车。</p><h3 id="docker安装open-webui" tabindex="-1"><a class="header-anchor" href="#docker安装open-webui"><span>docker安装open-webui</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如果下载太慢，可以使用a里云（非最新）的镜像地址。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always registry.cn-shenzhen.aliyuncs.com/funet8/open-webui:main</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>要运行支持 Nvidia GPU 的 Open WebUI，请使用以下命令：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如果您仅使用 OpenAI API，请使用以下命令：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker run -d -p 3000:8080 -e OPENAI_API_KEY=your_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如果仅适用于 CPU，不使用 GPU，请改用以下命令：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo/image-20240511173828471.png?aliyun" alt="image-20240511173828471"></p><h1 id="使用open-webui" tabindex="-1"><a class="header-anchor" href="#使用open-webui"><span>使用Open WebUI</span></a></h1><p>安装完成后，在Docker Desktop中可以看到Open WebUI的web界面地址为：https://localhost:3000</p><p>或者内网IP+端口，这样局域网的其他人也可以访问到</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511175350983.png?aliyun" alt="image-20240511175350983"></p><p>注册账号点击 sign up</p><p>登录</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511175608965.png?aliyun" alt="image-20240511175608965"></p><h3 id="设置为简体中文" tabindex="-1"><a class="header-anchor" href="#设置为简体中文"><span>设置为简体中文</span></a></h3><p>点击右上角的设置，可以修改当前界面的语言为简体中文：然后点击保存即可。</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511175737460.png?aliyun" alt="image-20240511175737460"></p><p>点击上方选择一个模型旁边的加号+可以增加大模型，点击下拉按钮可以选择当前使用哪一个已安装的模型，接下来就可以愉快的跟ai聊天了！</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511175902435.png?aliyun" alt="image-20240511175902435"></p><h1 id="使用llama2-3-8g" tabindex="-1"><a class="header-anchor" href="#使用llama2-3-8g"><span>使用llama2(3.8G)</span></a></h1><p>在power shell中输入</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run llama2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>安装完成如图：</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511180531152.png?aliyun" alt="image-20240511180531152"></p><p>在Open WebUI中会新增一个llama2:latest 7B</p><p><img src="https://imgoss.xgss.net/picgo/image-20240511180736354.png?aliyun" alt="image-20240511180736354"></p><h1 id="使用llama3-4-7g" tabindex="-1"><a class="header-anchor" href="#使用llama3-4-7g"><span>使用llama3(4.7G)</span></a></h1><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run llama3</span></span>
<span class="line"><span>ollama run llama3:8b</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo/image-20240513110343869.png?aliyun" alt="image-20240513110343869"></p><p>在Open WebUI中会新增一个llama3:latest 8B</p><p><img src="https://imgoss.xgss.net/picgo/image-20240513110414767.png?aliyun" alt="image-20240513110414767"></p><p><img src="https://imgoss.xgss.net/picgo/image-20240513110526936.png?aliyun" alt="image-20240513110526936"></p><h1 id="使用mistral-4-1g" tabindex="-1"><a class="header-anchor" href="#使用mistral-4-1g"><span>使用Mistral(4.1G)</span></a></h1><p>Mistral 7B 是 Mistral AI 发布的 70 亿参数语言模型。 Mistral 7B 是一种精心设计的语言模型，可提供高效和高性能以支持实际应用程序。 由于效率的提高，该模型适用于需要快速响应的实时应用。 发布时，Mistral 7B 在所有评估基准中均优于最佳开源 13B 模型 (Llama 2)。</p><p>安装：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run mistral</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo/image-20240513111621060.png?aliyun" alt="image-20240513111621060"></p><h1 id="使用gemma-5-0g" tabindex="-1"><a class="header-anchor" href="#使用gemma-5-0g"><span>使用gemma(5.0G)</span></a></h1><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run gemma</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo/image-20240513112439003.png?aliyun" alt="image-20240513112439003"></p><h1 id="使用qwen-14b-8-2g" tabindex="-1"><a class="header-anchor" href="#使用qwen-14b-8-2g"><span>使用qwen:14b(8.2G)</span></a></h1><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run qwen:14b</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo/image-20240513113857374.png?aliyun" alt="image-20240513113857374"></p><h1 id="在open-webui中拉取模型" tabindex="-1"><a class="header-anchor" href="#在open-webui中拉取模型"><span>在Open WebUI中拉取模型</span></a></h1><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>Open WebUI ---&gt; 设置---&gt;模型</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><img src="https://imgoss.xgss.net/picgo2025/image-20240515154450400.png?aliyun" alt="image-20240515154450400"></p><h1 id="结语" tabindex="-1"><a class="header-anchor" href="#结语"><span>结语</span></a></h1><p>安装Ollama完成之后就可以在本地愉快的使用大模型了。</p><p>例如支持gemma（谷歌大模型）、llama2和llama3（脸书大模型）、qwen（阿里大模型）等70+主流大模型，还在不断增加。</p><p>ollama官方的模型仓库参见这里：https://ollama.com/library</p>`,122)]))}const h=e(l,[["render",p]]),g=JSON.parse('{"path":"/article/w2lr5vxh/","title":"16.Windows系统下部署本地大语言模型","lang":"en-US","frontmatter":{"title":"16.Windows系统下部署本地大语言模型","createTime":"2025/05/27 17:51:17","permalink":"/article/w2lr5vxh/"},"git":{"createdTime":1749111496000,"updatedTime":1750129445000,"contributors":[{"name":"star","username":"star","email":"star@xgss.net","commits":2,"url":"https://github.com/star"}]},"readingTime":{"minutes":5.87,"words":1761},"filePathRelative":"chatgpt/16.Windows系统下部署本地大语言模型.md"}');export{h as comp,g as data};
