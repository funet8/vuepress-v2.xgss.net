# 基于Ollama+DeepSeek+AnythingLLM轻松投喂打造本地大模型知识库



大家好，我是星哥，上一篇文章星哥介绍了本地部署DeepSeek的方法：《[简单3步部署本地国产DeepSeek大模型](https://mp.weixin.qq.com/s/kJ7JCgFUNKWtPtp8r5mR_A)》。

今天继续讲利用Ollama+DeepSeek+AnythingLLM轻松投喂打造本地大模型知识库

![image-20250208183704501](https://imgoss.xgss.net/picgo/image-20250208183704501.png?aliyun)

# Ollama

## Ollama简介

Ollama 是一款提供本地部署和管理大模型的工具，可以轻松将不同的 AI 模型集成到本地环境中，并提供易于使用的界面和管理功能。你可以利用 Ollama 创建、启动和管理多个 AI 模型，并根据需要灵活配置不同的模型参数。

## 安装Ollama

参照 https://mp.weixin.qq.com/s/kJ7JCgFUNKWtPtp8r5mR_A 这篇文章安装

安装成功，查看版本和启动服务

```
查看版本：

PS C:\Users\Administrator\Desktop> ollama -v
ollama version is 0.5.7

查看大模型
PS C:\Users\Administrator\Desktop> ollama list
NAME                     ID              SIZE      MODIFIED
llama3-cn-8b:latest      d710bb08d58c    6.6 GB    23 hours ago
llama2-chinese:latest    cee11d703eee    3.8 GB    42 hours ago
deepseek-r1:14b          ea35dfe18182    9.0 GB    2 days ago
qwen2.5:latest           845dbda0ea48    4.7 GB    2 days ago
deepseek-r1:7b           0a8c26691023    4.7 GB    2 days ago
llama3:latest            365c0bd3c000    4.7 GB    2 days ago
```

# AnythingLLM



这是一个全栈应用程序，可以将任何文档、资源（如网址链接、音频、视频）或内容片段转换为上下文，以便任何大语言模型（LLM）在聊天期间作为参考使用。此应用程序允许您选择使用哪个LLM或向量数据库，同时支持多用户管理并设置不同权限。

开源中文： https://github.com/Mintplex-Labs/anything-llm/blob/master/locales/README.zh-CN.md



## 产品概览

AnythingLLM是一个全栈应用程序，您可以使用现成的商业大语言模型或流行的开源大语言模型，再结合向量数据库解决方案构建一个私有ChatGPT，不再受制于人：您可以本地运行，也可以远程托管，并能够与您提供的任何文档智能聊天。

AnythingLLM将您的文档划分为称为workspaces (工作区)的对象。工作区的功能类似于线程，同时增加了文档的容器化，工作区可以共享文档，但工作区之间的内容不会互相干扰或污染，因此您可以保持每个工作区的上下文清晰。

## AnythingLLM特性

- 多用户实例支持和权限管理
- 全新的可嵌入式聊天小部件，适用于您的网站
- 支持多种文档类型（PDF、TXT、DOCX等）
- 通过简单的用户界面管理您的向量数据库中的文档
- 两种聊天模式：对话模式和查询模式。对话模式保留之前的问题和修改记录。查询模式用于对您的文档进行简单的问答。
- 聊天中的引用文献功能
- 完全适用于云部署。
- "自带 LLM "模型。
- 极其高效的成本节约措施，用于管理非常大的文档。您将永远不会为嵌入的大型文档或转录付费超过一次。比其他文档聊天机器人解决方案更省成本，降低 90%。
- 提供完整的开发者 API，用于自定义集成！

## AnythingLLM下载与安装

下载： https://anythingllm.com/desktop

AnythingLLM也提供 macos、Window、Linux系统的下载

根据自己的系统下载，我这边下载Windows

![image-20250208173023447](https://imgoss.xgss.net/picgo/image-20250208173023447.png?aliyun)

下载文件之后点击安装

![image-20250208173941942](https://imgoss.xgss.net/picgo/image-20250208173941942.png?aliyun)

## AnythingLLM配置

AnythingLLM默认通过Ollama来使用LLama2 7B，Mistral 7B，Gemma 2B等模型，也可以调用OpenAI、Gemini、Mistral等大模型的API服务。

此前，我已经安装了Ollama，那么只要选择Ollama，输入调用的API接口URL，再选择此前已经下载的Gemma模型即可。

### 1.打开软件

get started

![image-20250208174317674](https://imgoss.xgss.net/picgo/image-20250208174317674.png?aliyun)

### 2.选择模型

这里选择Ollama并且选择 deepseek-r1:7B,这里选择你的已经安装的模型。

然后再点击向右的箭头，下一步。

![image-20250208174532563](https://imgoss.xgss.net/picgo/image-20250208174532563.png?aliyun)

### 3.下一步

点击下一步，这里不用配置。

![image-20250208174755881](https://imgoss.xgss.net/picgo/image-20250208174755881.png?aliyun)

### 4.填邮箱，可跳过

![image-20250208174832482](https://imgoss.xgss.net/picgo/image-20250208174832482.png?aliyun)

### 5.填入工作区名称

这里我随便取一个名字“产品计划”

![image-20250208174948521](https://imgoss.xgss.net/picgo/image-20250208174948521.png?aliyun)

### 修改聊天提示

这里把英文的聊天提示改成中文否则AI会用英文回答你。

![image-20250208175722804](https://imgoss.xgss.net/picgo/image-20250208175722804.png?aliyun)



# 生成文档

我这边用ai生成一个文档，写入本地成word，等下就让deepseek去学习这篇文章

> 你是一个互联网的产品经理
> 1.写一篇文章虚拟一个APP产品
> 2.这个产品集成了微信、微博、小红书、抖音、支付宝、Line、youtube等所有中外app的优点
> 3.文档不少于5000字
> 4.这个app的名字叫“宙斯app”，写一篇文档介绍它

文档名《宙斯APP：全能社交与支付平台的未来.docx》

![image-20250208175239105](https://imgoss.xgss.net/picgo/image-20250208175239105.png?aliyun)

# 投喂知识

## 1.点击上传按钮

![image-20250208175956673](https://imgoss.xgss.net/picgo/image-20250208175956673.png?aliyun)

## 2.上传文件

上传文件并且移动到工作区。

![image-20250208180151740](https://imgoss.xgss.net/picgo/image-20250208180151740.png?aliyun)



遇到问题

Error:1 documents failed toadd.
The specified module couldnot be found.\?\C:\ProgramFiles\AnythingLLM\resources\backend\node modules\onnxruntime-node\bin\napiv3\win32\x64\onnxruntime binding.node



![image-20250208180304121](https://imgoss.xgss.net/picgo/image-20250208180304121.png?aliyun)

解决办法：

在设置，点击Embedder ， 设置 Ollama 使用

![image-20250208182325588](https://imgoss.xgss.net/picgo/image-20250208182325588.png?aliyun)

## 3.再次导入文档

现在可以导入了，并且把图钉点上！

![image-20250208182605126](https://imgoss.xgss.net/picgo/image-20250208182605126.png?aliyun)

一定要把图钉点上！一定要把图钉点上！一定要把图钉点上！



![image-20250208182548315](https://imgoss.xgss.net/picgo/image-20250208182548315.png?aliyun)

# 对比使用

没有投喂文档的回答

![image-20250208182955547](https://imgoss.xgss.net/picgo/image-20250208182955547.png?aliyun)



这是投喂了文档的回答。

![image-20250208182838718](https://imgoss.xgss.net/picgo/image-20250208182838718.png?aliyun)

# 结束



通过将 Ollama、DeepSeek 和 AnythingLLM 三者结合，你可以轻松地构建一个本地大模型知识库。这种方法不仅能够帮助你高效地管理和组织信息，还能够提升你的工作效率，尤其是在处理海量文本、资料时，能够通过深度学习的能力快速找到最相关的内容。



写文不易，如果你都看到了这里，请点个赞和在看，分享给更多的朋友；也别忘了关注星哥玩云！这里有满满的干货分享，还有轻松有趣的技术交流～点个赞、分享给身边的小伙伴，一起成长，一起玩转技术世界吧！ 😊

