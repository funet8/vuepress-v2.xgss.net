---
title: 27.Ollama模型导入指南，从HuggingFace下载模型轻松上手
createTime: 2025/05/27 17:51:17
permalink: /article/zi0cwlf3/
---
# Ollama模型导入指南，从HuggingFace下载模型轻松上手



大家好，我是星哥，上一篇文章星哥介绍了本地部署DeepSeek的方法：《[简单3步部署本地国产DeepSeek大模型](https://mp.weixin.qq.com/s/kJ7JCgFUNKWtPtp8r5mR_A)》。

今天来讲不从[Ollama官网](https://ollama.com/)下载模型的方法，而是从HuggingFace下载，再导入模型。

![image-20250207204841747](https://imgoss.xgss.net/picgo/image-20250207204841747.png?aliyun)

# 一、安装ollama

参照 https://mp.weixin.qq.com/s/kJ7JCgFUNKWtPtp8r5mR_A 这篇文章安装ollama

## 1.查看ollama版本

```
ollama -v
ollama version is 0.5.7
```

## 2.下载模型



> 由于文件比较大，下载模型的时间花费比较长，
>
> 关注'星哥说事'，回复 'HuggingFace-llama3' 获得网盘下载地址。



Ollama可以直接下载内置的几种模型，但选择有限。我们更希望从[HuggingFace](https://huggingface.co/)下载以便方便地评估各种模型，所以，这里我们并不从Ollama直接下载，而是从HuggingFace下载。

在HuggingFace搜索`llama3`，设置`Languages`为`Chinese`，可以看到若干基于LLaMa3的中文模型：

直达地址： https://huggingface.co/zhouzr/Llama3-8B-Chinese-Chat-GGUF/tree/main

![image-20250207181753463](https://imgoss.xgss.net/picgo/image-20250207181753463.png?aliyun)

点击 Files and versions

![image-20250207181816429](https://imgoss.xgss.net/picgo/image-20250207181816429.png?aliyun)

下载 Llama3-8B-Chinese-Chat.q6_k.GGUF

GGUF格式的模型，GGUF格式是llama.cpp团队搞的一种模型存储格式，一个模型就是一个文件，llama.cpp的创始人Georgi Gerganov定义，旨在解决当前大模型在实际应用中遇到的存储效率、加载速度、兼容性和扩展性等问题。

![image-20250207181848645](https://imgoss.xgss.net/picgo/image-20250207181848645.png?aliyun)

## 3.导入模型

需要编写一个配置文件，随便起个名字，如ollama_Liama3_config.txt

文件放到D盘下的ollama目录中

配置文件内容如下：

```
FROM "D:\ollama\Llama3-8B-Chinese-Chat.q6_k.GGUF"

TEMPLATE """{{- if .System }}
<|im_start|>system {{ .System }}<|im_end|>
{{- end }}
<|im_start|>user
{{ .Prompt }}<|im_end|>
<|im_start|>assistant
"""

SYSTEM """"""

PARAMETER stop <|im_start|>
PARAMETER stop <|im_end|>
```

![image-20250207183237880](https://imgoss.xgss.net/picgo/image-20250207183237880.png?aliyun)

导入模型命令

```
PS D:\ollama> ollama create llama3-cn-8b -f ./ollama_Liama3_config.txt
gathering model components
copying file sha256:e0e83a7967c61e38d6a3fd8b093754117944b405d35afe95f129fbfb143929f2 100%
parsing GGUF
using existing layer sha256:e0e83a7967c61e38d6a3fd8b093754117944b405d35afe95f129fbfb143929f2
creating new layer sha256:b65f5bb03e74da8572e4191596a895bddc10355595c38574a16fdf12a889855b
creating new layer sha256:f02dd72bb2423204352eabc5637b44d79d17f109fdb510a7c51455892aa2d216
writing manifest
success
```



查看模型

```
ollama list
NAME                     ID              SIZE      MODIFIED
llama3-cn-8b:latest      d710bb08d58c    6.6 GB    About a minute ago
llama2-chinese:latest    cee11d703eee    3.8 GB    19 hours ago
deepseek-r1:14b          ea35dfe18182    9.0 GB    27 hours ago
qwen2.5:latest           845dbda0ea48    4.7 GB    40 hours ago
deepseek-r1:7b           0a8c26691023    4.7 GB    42 hours ago
llama3:latest            365c0bd3c000    4.7 GB    45 hours ago
```

llama3-cn-8b:latest 则导入成功

## 运行模型

使用Ollama的`run`命令可以直接运行模型。我们输入命令

```
ollama run llama3-cn-8b
```

![image-20250207183706904](https://imgoss.xgss.net/picgo/image-20250207183706904.png?aliyun)

# 在Open WebUI使用



![image-20250207183938856](https://imgoss.xgss.net/picgo/image-20250207183938856.png?aliyun)

# 总结

通过 Ollama，你可以轻松地在本地运行 Hugging Face 模型。Ollama 提供了简单易用的命令行界面，让你能够快速上手。希望本指南能够帮助你成功导入并运行 Hugging Face 模型。



写文不易，如果你都看到了这里，请点个赞和在看，分享给更多的朋友；也别忘了关注星哥玩云！这里有满满的干货分享，还有轻松有趣的技术交流～点个赞、分享给身边的小伙伴，一起成长，一起玩转技术世界吧！ 😊

