# Linux常用命令完全指南：从入门到精通，一篇文章搞定所有场景



## 引言：为什么你需要掌握这些Linux命令？

作为一名运维工程师，我在过去10年里处理过无数生产环境事故，其中80%的问题都是通过几个核心Linux命令快速定位和解决的。今天，我将把这些年积累的Linux命令精华全部分享给你，让你少走5年弯路。

无论你是刚入行的运维新手，还是想提升效率的老鸟，这篇文章都会给你带来实实在在的价值。我会用最实战的角度，配合真实的生产场景，让你不仅会用命令，更懂得什么时候用、怎么用最高效。

## 一、文件和目录操作：运维日常的基石

### 1.1 基础导航命令

在Linux世界里，一切皆文件。掌握文件系统的导航是你的第一步。

```
# pwd - 显示当前工作目录
$ pwd
/home/admin/logs

# cd - 切换目录（这些技巧90%的人不知道）
$ cd -           # 快速返回上一个工作目录
$ cd ~username   # 进入指定用户的home目录
$ cd !$          # 进入上一条命令的最后一个参数（超实用）

# ls - 列出目录内容（高级用法）
$ ls -lhtr       # 按时间倒序显示，人类可读格式
$ ls -ld */      # 只显示目录
$ ls -la | grep "^d"  # 只显示目录（另一种方法）
```

**实战技巧**：当你在排查生产问题时，经常需要在多个日志目录间切换。使用 `pushd` 和 `popd` 可以维护一个目录栈：

```
$ pushd /var/log/nginx    # 保存当前目录并跳转
$ pushd /var/log/mysql    
$ dirs -v                  # 查看目录栈
$ popd                     # 返回上一个目录
```

### 1.2 文件操作进阶

```
# find - 查找文件（运维必备神器）
$ find /var/log -name "*.log" -mtime +7 -size +100M -execrm {} \;
# 删除7天前大于100M的日志文件

$ find . -type f -name "*.conf" -exec grep -l "error" {} \;
# 查找包含"error"的配置文件

$ find /data -type f -mmin -5
# 查找5分钟内修改过的文件（排查问题神器）

# cp/mv/rm 的安全用法
$ cp -av source/ dest/     # 保留所有属性，显示详细信息
$ mv -i file1 file2        # 交互式移动，避免误操作
$ rm -I *.log              # 删除多个文件时提示确认

# rsync - 高效同步（比cp/scp强大100倍）
$ rsync -avzP --delete source/ dest/
# -a: 归档模式  -v: 详细输出  -z: 压缩传输  -P: 显示进度
# --delete: 删除目标多余文件（慎用）

$ rsync -avz --exclude='*.log' --exclude='cache/'source/ dest/
# 排除特定文件或目录
```

### 1.3 文件内容查看技巧

```
# less/more 的高级用法
$ less +F /var/log/messages   # 类似tail -f，但可以随时切换
# 按 Ctrl+C 停止跟踪，按 F 继续跟踪

# head/tail 组合技
$ tail -n +100 file.txt | head -n 50
# 显示文件第100-150行

$ tail -f /var/log/nginx/access.log | grep --line-buffered "ERROR"
# 实时过滤错误日志

# cat 的特殊用法
$ cat -A file.txt    # 显示所有特殊字符（调试格式问题）
$ cat > file.txt << EOF
多行内容
直接写入
EOF
```

## 二、文本处理三剑客：grep、sed、awk

这三个命令是Linux文本处理的核心，掌握它们等于掌握了数据处理的瑞士军刀。

### 2.1 grep - 文本搜索利器

```
# grep 高级技巧
$ grep -B 3 -A 3 "ERROR" app.log   # 显示匹配行的前后3行
$ grep -v "^#\|^$" config.conf     # 过滤注释和空行
$ grep -r --include="*.java" "TODO" .  # 递归搜索特定文件类型

# 实用正则表达式
$ grep -E "^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}" access.log
# 匹配IP地址

$ grep -oP '(?<=user_id=)[0-9]+' access.log | sort -u
# 提取所有唯一的user_id

# 性能优化技巧
$ LC_ALL=C grep pattern file    # 使用C语言环境，提速30%
$ grep -F "fixed_string" file   # 固定字符串搜索，更快
```

### 2.2 sed - 流编辑器

```
# sed 实战案例
$ sed -i.bak 's/old/new/g' file.txt   # 替换并备份原文件
$ sed -n '100,200p' huge_file.txt     # 只显示100-200行
$ sed '/^$/d' file.txt                # 删除空行

# 批量修改配置文件
$ sed -i 's/^#\(.*nginx.*\)/\1/g' config.conf
# 取消包含nginx的注释行

# 高级应用
$ sed -n '/START/,/END/p' file.txt    # 打印两个模式之间的内容
$ sed '1~2d' file.txt                  # 删除奇数行
$ sed -e 's/^/PREFIX_/' -e 's/$/_SUFFIX/' file.txt
# 同时添加前缀和后缀
```

### 2.3 awk - 数据处理专家

```
# awk 核心用法
$ awk '{sum+=$5} END {print sum/NR}' data.txt
# 计算第5列的平均值

$ awk '$3 > 1000 {print $1, $3}' access.log
# 打印第3列大于1000的行

# 日志分析实例
$ awk '{print $1}' access.log | sort | uniq -c | sort -rn | head -10
# 统计访问最多的10个IP

$ awk -F: '$3 >= 1000 {print $1}' /etc/passwd
# 查找UID大于等于1000的用户

# 高级技巧
$ awk 'BEGIN{OFS=","} {$1=$1; print}' file.txt
# 将空格分隔转换为逗号分隔

$ awk 'NR==FNR{a[$1]=$2;next} {print $0, a[$1]}' file1 file2
# 类似SQL的JOIN操作
```

## 三、系统监控与性能分析

### 3.1 进程管理命令

```
# ps 的实用技巧
$ ps aux --sort=-%cpu | head -10      # CPU占用最高的10个进程
$ ps aux --sort=-%mem | head -10      # 内存占用最高的10个进程
$ ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head
# 自定义输出格式

# 查找特定进程
$ ps -ef | grep "[n]ginx"    # 方括号技巧，避免grep自己
$ pgrep -f "java.*tomcat"    # 更优雅的方式
$ pidof nginx                # 获取进程PID

# kill 的正确姿势
$ kill -TERM $pid    # 优雅终止（默认）
$ kill -HUP $pid     # 重新加载配置
$ kill -USR1 $pid    # 用户自定义信号（如nginx日志切割）
$ timeout 5 some_command    # 限时执行命令
```

### 3.2 系统资源监控

```
# top/htop 高级用法
$ top -b -n 1 | head -20    # 批处理模式，适合脚本
$ top -p $(pgrep -d',' java)  # 监控所有java进程

# vmstat - 虚拟内存统计
$ vmstat 1 10    # 每秒输出一次，共10次
# r: 运行队列  b: 阻塞进程  swpd: 使用的交换空间
# si/so: 交换进出  bi/bo: 块设备IO

# iostat - IO统计
$ iostat -x 1    # 详细IO统计
# %util: 设备利用率，接近100%说明IO瓶颈

# sar - 系统活动报告
$ sar -u 1 10         # CPU使用率
$ sar -r 1 10         # 内存使用
$ sar -n DEV 1 10     # 网络流量
$ sar -d 1 10         # 磁盘IO
```

### 3.3 网络诊断命令

```
# netstat/ss 网络连接分析
$ ss -tulpn | grep :80    # 查看80端口监听情况（比netstat快）
$ ss -ant | awk '{print $1}' | sort | uniq -c
# 统计TCP连接状态

$ netstat -an | grep ESTABLISHED | wc -l
# 统计已建立的连接数

# tcpdump 抓包分析
$ tcpdump -i eth0 -nn host 192.168.1.100 and port 80
# 抓取特定主机和端口的包

$ tcpdump -i any -w capture.pcap -C 100 -W 10
# 循环保存10个100MB的文件

# 网络性能测试
$ curl -w "@curl-format.txt" -o /dev/null -s https://example.com
# 详细的HTTP性能指标

$ nc -zv hostname 22-80    # 扫描端口范围
$ nmap -sV -p- hostname     # 全端口扫描
```

## 四、日志分析与故障排查

### 4.1 日志分析技巧

```
# 统计错误出现次数
$ grep "ERROR" app.log | awk '{print $5}' | sort | uniq -c | sort -rn

# 按时间段分析日志
$ awk '$1 >= "2024-01-01" && $1 <= "2024-01-31"' access.log

# 实时监控多个日志
$ tail -f /var/log/{nginx/*.log,mysql/*.log}

# 日志轮转处理
$ zcat access.log.*.gz | grep "pattern"    # 搜索压缩日志
$ zless access.log.gz                       # 查看压缩日志

# 高级日志分析
$ awk '/ERROR/{print $0; for(i=1; i<=3; i++) {getline; print}}' app.log
# 打印ERROR及后续3行
```

### 4.2 故障排查实战

```
# 磁盘空间问题
$ df -h | awk '$5+0 > 80'    # 使用率超过80%的分区
$ du -sh /* 2>/dev/null | sort -rh | head -10    # 根目录下最大的10个目录
$ find / -size +1G -type f 2>/dev/null    # 查找大于1G的文件

# 内存问题排查
$ free -h | awk '/^Mem:/ {print "Used: " $3 "/" $2 " (" $3/$2*100 "%)"}'
$ ps aux | awk '{sum+=$6} END {print "Total RSS: " sum/1024 " MB"}'

# CPU问题定位
$ mpstat -P ALL 1    # 查看每个CPU核心使用情况
$ pidstat -u 1 10    # 查看进程CPU使用情况

# 网络连接问题
$ ss -s    # 连接统计摘要
$ conntrack -L | wc -l    # 查看连接跟踪表大小
```

## 五、Shell脚本最佳实践

### 5.1 脚本编写技巧

```
#!/bin/bash
# 脚本模板

set -euo pipefail    # 严格模式
IFS=$'\n\t'         # 设置内部字段分隔符

# 错误处理
trap'echo "Error on line $LINENO"' ERR

# 日志函数
log() {
    echo"[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a /var/log/script.log
}

# 参数检查
if [ $# -lt 1 ]; then
    echo"Usage: $0 <argument>"
    exit 1
fi

# 并发控制
MAX_JOBS=5
for item in"${items[@]}"; do
    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do
        sleep 1
    done
    process_item "$item" &
done
wait
```

### 5.2 实用Shell函数库

```
# 重试机制
retry() {
    local max_attempts="$1"
    local delay="$2"
    local count=0
    shift 2
    
    until"$@"; do
        count=$((count + 1))
        if [ $count -ge $max_attempts ]; then
            echo"Command failed after $count attempts"
            return 1
        fi
        echo"Attempt $count failed, retrying in ${delay}s..."
        sleep"$delay"
    done
}

# 使用示例
retry 3 5 curl -f http://example.com

# 彩色输出
red() { echo -e "\033[31m$*\033[0m"; }
green() { echo -e "\033[32m$*\033[0m"; }
yellow() { echo -e "\033[33m$*\033[0m"; }

# 进度条
progress_bar() {
    local duration=$1
    local steps=50
    local sleep_time=$(echo"scale=3; $duration / $steps" | bc)
    
    for i in $(seq 1 $steps); do
        printf"\r["
        printf"%0.s=" $(seq 1 $i)
        printf"%0.s " $(seq$i $((steps-1)))
        printf"] %d%%" $((i*100/steps))
        sleep$sleep_time
    done
    echo
}
```

## 六、容器与云原生运维

### 6.1 Docker常用命令

```
# Docker容器管理
$ docker ps -a --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
# 自定义输出格式

$ docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
# 查看资源使用情况

$ docker system prune -a --volumes    # 清理所有未使用资源
$ docker logs -f --tail 100 container_name    # 实时查看日志

# 批量操作
$ docker stop $(docker ps -aq)    # 停止所有容器
$ docker rm $(docker ps -aq -f status=exited)    # 删除已停止容器

# 调试技巧
$ docker exec -it container_name /bin/bash    # 进入容器
$ docker cp container:/path/to/file ./    # 从容器复制文件
$ docker diff container_name    # 查看容器文件系统变化
```

### 6.2 Kubernetes运维命令

```
# Pod管理
$ kubectl get pods -A --sort-by='.status.startTime'
$ kubectl top pods --all-namespaces | sort -k3 -rn | head
$ kubectl describe pod pod_name -n namespace

# 日志查看
$ kubectl logs -f deployment/app --all-containers=true
$ kubectl logs pod_name --previous    # 查看崩溃前的日志

# 资源管理
$ kubectl get events --sort-by='.lastTimestamp' -A
$ kubectl rollout history deployment/app
$ kubectl set image deployment/app app=image:tag --record

# 调试命令
$ kubectl exec -it pod_name -- /bin/bash
$ kubectl port-forward pod/pod_name 8080:80
$ kubectl debug pod_name -it --image=busybox
```

## 七、安全加固与审计

### 7.1 系统安全检查

```
# 用户和权限审计
$ find / -perm -4000 -type f 2>/dev/null    # 查找SUID文件
$ find / -perm -2000 -type f 2>/dev/null    # 查找SGID文件
$ find / -nouser -o -nogroup 2>/dev/null    # 无主文件

# 登录审计
$ last -10    # 最近10次登录
$ lastb       # 失败的登录尝试
$ who -H      # 当前登录用户
$ w           # 详细的用户活动

# 文件完整性检查
$ find /etc -type f -mtime -1    # 24小时内修改的配置文件
$ rpm -Va    # RPM包文件完整性检查（RedHat系）
$ debsums    # DEB包文件完整性检查（Debian系）
```

### 7.2 网络安全监控

```
# 防火墙规则管理
$ iptables -L -n -v --line-numbers    # 查看详细规则
$ iptables -I INPUT 1 -s IP -j DROP   # 封禁IP
$ iptables -D INPUT 1                 # 删除规则

# 连接监控
$ ss -tupn | grep LISTEN    # 监听端口
$ lsof -i :80              # 查看80端口的进程
$ netstat -tulpn | grep -v 127.0.0.1    # 外部监听端口

# 入侵检测
$ grep "Failed password" /var/log/secure | awk '{print $11}' | sort | uniq -c | sort -rn
# SSH暴力破解统计

$ tcpdump -nn -c 100 'tcp[tcpflags] == tcp-syn'
# 监控SYN包（可能的SYN flood）
```

## 八、性能优化实战

### 8.1 系统调优命令

```
# 内核参数优化
$ sysctl -a | grep net.ipv4    # 查看网络参数
$ echo"net.ipv4.tcp_fin_timeout = 30" >> /etc/sysctl.conf
$ sysctl -p    # 立即生效

# 文件句柄限制
$ ulimit -a                      # 查看当前限制
$ ulimit -n 65535                # 临时修改
$ echo"* soft nofile 65535" >> /etc/security/limits.conf

# IO调度器优化
$ cat /sys/block/sda/queue/scheduler
$ echo deadline > /sys/block/sda/queue/scheduler

# CPU亲和性设置
$ taskset -c 0-3 command    # 绑定到CPU 0-3
$ taskset -p -c 0,1 PID     # 绑定进程到特定CPU
```

### 8.2 服务优化示例

```
# Nginx优化检查
$ nginx -t    # 配置语法检查
$ nginx -T    # 显示完整配置
$ ab -n 10000 -c 100 http://localhost/    # 压力测试

# MySQL优化
$ mysql -e "SHOW VARIABLES LIKE '%buffer%'"
$ mysql -e "SHOW STATUS LIKE 'Threads%'"
$ mysqladmin processlist
$ mysqltuner    # MySQL调优建议工具

# Redis性能监控
$ redis-cli --latency    # 延迟监控
$ redis-cli --bigkeys    # 查找大key
$ redis-cli monitor      # 实时命令监控
```

## 九、自动化运维工具

### 9.1 定时任务管理

```
# crontab高级用法
$ crontab -l | grep -v '^#' | grep -v '^$'    # 查看活动任务
$ crontab -l > backup.cron && crontab -r       # 备份并清除

# 特殊时间表达式
@reboot    # 系统启动时执行
@yearly    # 每年执行一次
@monthly   # 每月执行一次
@weekly    # 每周执行一次
@daily     # 每天执行一次
@hourly    # 每小时执行一次

# 任务输出重定向
*/5 * * * * /path/to/script.sh >> /var/log/cron.log 2>&1
# 或者完全静默
*/5 * * * * /path/to/script.sh > /dev/null 2>&1
```

### 9.2 批量操作技巧

```
# 并行执行
$ cat hosts.txt | xargs -P 10 -I {} ssh {} "uptime"
# 对多台主机并行执行命令

# GNU Parallel更强大
$ parallel -j 10 ssh {} uptime :::: hosts.txt
$ find . -name "*.jpg" | parallel -j 8 convert {} {.}.png

# 批量文件处理
$ for f in *.txt; domv"$f""${f%.txt}.bak"; done
$ rename 's/\.txt$/\.md/' *.txt    # 批量重命名

# SSH批量执行
$ pssh -h hosts.txt -l root -i "hostname; uptime"
$ pdsh -w node[01-10] "systemctl restart nginx"
```

## 十、故障恢复与数据备份

### 10.1 数据备份策略

```
# tar备份
$ tar -czf backup-$(date +%F).tar.gz --exclude='*.log' /data/
$ tar --listed-incremental=snapshot.snar -czf incremental.tar.gz /data/

# rsync增量备份
$ rsync -avz --backup --backup-dir=/backup/$(date +%F) source/ dest/
$ rsync -avz --link-dest=/backup/yesterday/ source/ /backup/today/

# 数据库备份
$ mysqldump -u root -p --all-databases --single-transaction > backup.sql
$ pg_dumpall -U postgres > postgres_backup.sql

# 备份验证
$ tar -tzf backup.tar.gz | head    # 查看备份内容
$ mysql test < backup.sql           # 恢复测试
```

### 10.2 灾难恢复

```
# 文件恢复
$ extundelete /dev/sda1 --restore-file /path/to/file
$ testdisk /dev/sda    # 分区恢复工具

# 进程恢复
$ gcore -o dump PID    # 生成进程core dump
$ gdb /path/to/program dump.PID    # 分析dump

# 系统恢复
$ systemctl rescue     # 进入救援模式
$ systemctl emergency  # 进入紧急模式
$ init 1              # 单用户模式

# 网络恢复
$ ip linkset eth0 up
$ dhclient eth0
$ ip addr add 192.168.1.100/24 dev eth0
$ ip route add default via 192.168.1.1
```

## 实战案例：一次生产环境故障处理

让我分享一个真实的案例，展示这些命令如何在实战中组合使用：

**场景**：凌晨3点，收到告警，网站响应极慢。

**排查过程**：

```
# 1. 快速检查系统负载
$ uptime
load average: 28.43, 22.17, 15.89    # 负载异常高

# 2. 查看CPU占用
$ top -b -n 1 | head -20
# 发现mysql进程CPU占用300%

# 3. 检查MySQL慢查询
$ tail -100 /var/log/mysql/slow.log
# 发现大量全表扫描

# 4. 查看当前MySQL进程
$ mysql -e "show processlist" | grep -v Sleep
# 发现某个查询运行了1800秒

# 5. 紧急处理
$ mysql -e "kill query_id"    # 杀掉慢查询

# 6. 分析访问日志
$ awk '{print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -rn | head
# 发现某IP异常访问

# 7. 临时封禁
$ iptables -I INPUT -s suspicious_ip -j DROP

# 8. 监控恢复情况
$ watch -n 1 'uptime; ss -s; mysql -e "show status like \"Threads%\""'
```

整个过程15分钟内完成定位和处理，这就是熟练掌握Linux命令的威力。

## 进阶学习资源

### 必读书籍推荐

- • 《Linux Command Line and Shell Scripting Bible》
- • 《UNIX and Linux System Administration Handbook》
- • 《Site Reliability Engineering》(Google SRE)

### 在线练习平台

- • Linux Survival：交互式Linux命令学习
- • OverTheWire：通过游戏学习Linux安全
- • HackerRank Shell：Shell脚本编程挑战

### 持续学习建议

1. \1. **建立自己的命令库**：把常用的命令组合记录下来，形成自己的工具箱
2. \2. **阅读man页面**：养成查看man page的习惯，很多隐藏功能都在里面
3. \3. **关注性能**：不仅要会用，还要知道哪个命令更高效
4. \4. **自动化思维**：能脚本化的绝不手动，提高效率
5. \5. **安全意识**：每个命令都要考虑安全影响