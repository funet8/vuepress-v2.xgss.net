# 如何部署企业级ELK + Kafka + Filebeat

## . 背景与架构设计

在企业级日志平台中，**ELK（Elasticsearch + Logstash + Kibana）** 是核心分析与可视化组件，而 **Kafka** 作为高吞吐消息队列，能有效解耦日志采集与处理，**Filebeat** 则是轻量级日志采集器。 典型架构如下：

```
[业务服务器] 
    ↓ Filebeat
[Kafka 集群] 
    ↓ Logstash
[Elasticsearch 集群] 
    ↓ Kibana
[可视化与告警]
```

![image-20250831230714174](https://imgoss.xgss.net/picgo-tx2025/image-20250831230714174.png?tx)

**优势：**

- **高可用**：Kafka 缓冲防止 ES 短暂不可用导致数据丢失
- **可扩展**：任意扩展采集端、处理端、存储端
- **实时性**：秒级日志采集与查询
- **解耦**：采集、传输、处理、存储各自独立

## 2. 环境规划

| 角色               | 节点数量 | 示例 IP           | 主要组件              |
| ------------------ | -------- | ----------------- | --------------------- |
| ES Master + Kibana | 1        | 192.168.1.130     | Elasticsearch、Kibana |
| ES Data Node       | 2        | 192.168.1.131-132 | Elasticsearch         |
| Kafka Broker       | 3        | 192.168.1.140-142 | Kafka、Zookeeper      |
| Logstash           | 2        | 192.168.1.150-151 | Logstash              |
| Filebeat           | N        | 各业务服务器      | Filebeat              |

**版本建议：**

- Elasticsearch / Logstash / Kibana：7.17.x（稳定且长期支持）
- Kafka：2.8.x 或 3.x（与 Filebeat Kafka Output 兼容）
- Filebeat：与 ELK 版本保持一致

## 3. 部署步骤

### 3.1 部署 Kafka 集群

1. **安装 Zookeeper（可用 Kafka 自带）**

   ```
   tar -xf kafka_2.13-2.8.0.tgz -C /opt/
   vim config/zookeeper.properties
   dataDir=/data/zookeeper
   clientPort=2181
   ```

   启动：

   bash

   ```
   bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
   ```

2. **安装 Kafka Broker**

   ```
   vim config/server.properties
   broker.id=1
   listeners=PLAINTEXT://192.168.1.140:9092
   log.dirs=/data/kafka-logs
   zookeeper.connect=192.168.1.140:2181,192.168.1.141:2181,192.168.1.142:2181
   ```

   启动：

   ```
   bin/kafka-server-start.sh -daemon config/server.properties
   ```

3. **创建日志 Topic**

   ```
   bin/kafka-topics.sh --create --zookeeper 192.168.1.140:2181 \
       --replication-factor 2 --partitions 3 --topic logs
   ```

### 3.2 部署 Elasticsearch 集群

1. **系统优化**

   ```
   echo "vm.max_map_count=262144" >> /etc/sysctl.conf
   sysctl -p
   ulimit -n 65535
   ```

2. **配置 elasticsearch.yml**

   yaml

   ```
   cluster.name: es-cluster
   node.name: es-node-1
   path.data: /data/elasticsearch
   path.logs: /var/log/elasticsearch
   network.host: 192.168.1.130
   discovery.seed_hosts: ["192.168.1.130","192.168.1.131","192.168.1.132"]
   cluster.initial_master_nodes: ["es-node-1","es-node-2","es-node-3"]
   ```

3. **启动并验证**

   ```
   ./bin/elasticsearch -d
   curl http://192.168.1.130:9200/_cluster/health?pretty
   ```

### 3.3 部署 Kibana

yaml

```
server.host: "0.0.0.0"
elasticsearch.hosts: ["http://192.168.1.130:9200"]
i18n.locale: "zh-CN"
```

启动：

bash

```
./bin/kibana &
```

### 3.4 部署 Logstash

1. **安装插件**

   ```
   bin/logstash-plugin install logstash-input-kafka
   ```

2. **配置 logstash.conf**

   ```
   input {
     kafka {
       bootstrap_servers => "192.168.1.140:9092,192.168.1.141:9092,192.168.1.142:9092"
       topics => ["logs"]
       group_id => "logstash-group"
       codec => "json"
     }
   }
   filter {
     json { source => "message" }
   }
   output {
     elasticsearch {
       hosts => ["http://192.168.1.130:9200"]
       index => "logs-%{+YYYY.MM.dd}"
     }
   }
   ```

### 3.5 部署 Filebeat

```
filebeat.inputs:
  - type: log
    paths:
      - /var/log/nginx/access.log
      - /var/log/nginx/error.log

output.kafka:
  hosts: ["192.168.1.140:9092","192.168.1.141:9092","192.168.1.142:9092"]
  topic: "logs"
  partition.round_robin:
    reachable_only: true
  required_acks: 1
  compression: gzip
```

启动：

```
./filebeat -e -c filebeat.yml
```

## 4. 企业级优化建议

- **Kafka**
  - 开启 `log.retention.hours` 控制日志保留时间
  - 使用多分区提升并发消费能力
- **Elasticsearch**
  - 使用冷热分离（Hot/Warm/Cold 节点）
  - 定期 rollover + ILM（Index Lifecycle Management）
- **Logstash**
  - 多 pipeline 并行处理
  - 使用持久化队列（persistent queue）
- **Filebeat**
  - 启用 `bulk_max_size` 优化批量发送
  - 使用多 prospector 分流不同日志类型
- **安全**
  - 启用 Kafka + ES 的 SASL/SSL
  - Kibana 配置用户权限（X-Pack）

## 5. 验证与监控

- **验证数据流**：在 Kibana Discover 中搜索日志
- **监控组件**：
  - Kafka：`kafka-topics.sh --describe`
  - Elasticsearch：`/_cluster/health`
  - Filebeat：`filebeat -e -d "publish"`
- **告警**：可接入 ElastAlert、Prometheus + Alertmanager

## 6. 总结

通过 **Filebeat → Kafka → Logstash → Elasticsearch → Kibana** 的链路，可以构建一个高可用、可扩展、实时的企业级日志分析平台。Kafka 的引入不仅提升了系统的抗压能力，还为后续接入多种消费端（如大数据分析、实时告警）提供了可能性。