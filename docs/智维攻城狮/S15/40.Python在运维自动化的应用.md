# Python运维脚本：Python在运维自动化的应用



在当下云计算、容器化和DevOps盛行的时代，运维工作早已从“手工敲命令”演变为“代码即基础设施”。而Python凭借其语法简洁、生态丰富、学习曲线平缓等特性，几乎成为了运维自动化领域的“事实标准”语言。无论是批量管理几百台上千台服务器，还是实现复杂的配置管理、监控告警、日志分析，Python都能轻松胜任。

本文将从实际运维场景出发，系统介绍Python在自动化运维中的核心应用方向，并提供大量真实可用的代码示例，帮助你快速上手。

## 一、为什么运维工程师要选择Python？

| 优势                           | 具体体现                                                     |
| ------------------------------ | ------------------------------------------------------------ |
| 语法简单                       | 10行Python代码 ≈ 50行Shell/Bash                              |
| 电池内置（Batteries Included） | 标准库就涵盖了文件、网络、进程、正则、多线程等运维常用功能   |
| 第三方库极其丰富               | paramiko、fabric、ansible、psutil、requests、pandas、saltstack、openstack sdk等 |
| 跨平台                         | Windows、Linux、macOS统一写法                                |
| 社区活跃                       | 几乎所有主流运维工具都提供Python SDK或直接用Python开发（Ansible、SaltStack、OpenStack、Kubernetes client） |



## 二、Python运维自动化的典型场景

### 1. 批量执行远程命令（替代ssh循环）

最经典的场景：对几百台机器批量执行命令、收集信息。

```python
# batch_ssh_exec.py
import paramiko
import threading
import queue
import time

# 任务队列
task_queue = queue.Queue()
result_dict = {}

def ssh_exec(host, username='root', password='yourpass', command='uptime'):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    try:
        client.connect(host, username=username, password=password, timeout=10)
        stdin, stdout, stderr = client.exec_command(command)
        output = stdout.read().decode('utf-8')
        error = stderr.read().decode('utf-8')
        result_dict[host] = {'output': output, 'error': error, 'status': 'success'}
    except Exception as e:
        result_dict[host] = {'error': str(e), 'status': 'failed'}
    finally:
        client.close()

# 读取IP列表
with open('hosts.txt') as f:
    hosts = [line.strip() for line in f if line.strip()]

# 放入队列
for host in hosts:
    task_queue.put(host)

# 启动线程池
threads = []
for i in range(50):  # 并发50个
    t = threading.Thread(target=lambda: ssh_exec(task_queue.get(), command='df -h') if not task_queue.empty() else None)
    t.start()
    threads.append(t)

# 等待完成
for t in threads:
    t.join()

# 输出结果
for host, res in result_dict.items():
    print(f"{host}: {res['status']}")
    if res['status'] == 'success':
        print(res['output'])
```

进阶推荐：使用Fabric（基于paramiko的高级封装）或Ansible的Python API。

```python
# 使用Fabric（更优雅）
from fabric import Connection, SerialGroup, ThreadingGroup

hosts = ['192.168.1.{}'.format(i) for i in range(10, 20)]
# 串行执行
for conn in SerialGroup(*hosts, user='root', connect_kwargs={"password": "xxx"}):
    result = conn.run('hostname -I', hide=True)
    print(f"{conn.host}: {result.stdout.strip()}")

# 并行执行（推荐）
results = ThreadingGroup(*hosts, user='root', connect_kwargs={"password": "xxx"}).run('uptime', hide=True)
for conn, result in results.items():
    print(conn, result.stdout.strip())
```

### 2. 配置文件批量管理（批量替换、检查）

```python
# config_replace.py
import os
import re
import hashlib

def md5(file_path):
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def batch_replace(config_dir, old_str, new_str, suffix='.conf'):
    for root, dirs, files in os.walk(config_dir):
        for file in files:
            if file.endswith(suffix):
                filepath = os.path.join(root, file)
                backup = filepath + '.bak.' + md5(filepath)[:8]
                os.system(f'cp {filepath} {backup}')  # 备份
                
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                new_content = content.replace(old_str, new_str)
                
                if content != new_content:
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    print(f"[修改] {filepath}")
                else:
                    print(f"[无变更] {filepath}")
```

### 3. 服务器信息采集与报告生成

```python
# server_report.py
import psutil
import platform
import socket
import json
from datetime import datetime

def collect_info():
    info = {
        "timestamp": datetime.now().isoformat(),
        "hostname": socket.gethostname(),
        "ip": socket.gethostbyname(socket.gethostname()),
        "system": platform.platform(),
        "cpu_percent": psutil.cpu_percent(interval=1),
        "memory": psutil.virtual_memory._asdict(),
        "disk": {mount: psutil.disk_usage(mount)._asdict() for mount in ['/', '/data'] if os.path.exists(mount)},
        "loadavg": psutil.getloadavg(),
    }
    return info

report = collect_info()
with open(f"/tmp/report_{socket.gethostname()}.json", "w") as f:
    json.dump(report, f, indent=2)

# 配合上面批量执行脚本，就可以收集全网服务器信息
```

### 4. 日志实时分析与告警

```python
# log_monitor.py
import time
import re
from collections import defaultdict

error_counter = defaultdict(int)
pattern = re.compile(r'ERROR|Exception|Failed|timeout', re.I)

def tail_f(filename):
    with open(filename) as f:
        f.seek(0, 2)  # 文件末尾
        while True:
            line = f.readline()
            if not line:
                time.sleep(0.1)
                continue
            yield line

for line in tail_f('/var/log/nginx/access.log'):
    if pattern.search(line):
        error_counter[line.split()[8]] += 1  # 按状态码统计
        print(f"告警: {line.strip()}")
        
        # 简单钉钉/企业微信告警
        if error_counter['500'] > 10:
            requests.post("https://oapi.dingtalk.com/robot/send?access_token=xxx",
                          json={"msgtype": "text", "text": {"content": "Nginx 500告警！"}})
```

### 5. 自动化部署与蓝绿/金丝雀发布

```python
# deploy.py（简化版蓝绿部署）
from fabric import Connection

def deploy_blue():
    c = Connection('deploy@blue-server')
    with c.cd('/apps/myapp'):
        c.run('git pull')
        c.run('supervisorctl restart myapp')

def deploy_green():
    c = Connection('deploy@green-server')
    # 同上

def switch_traffic_to_green():
    c = Connection('lb-server')
    c.run('nginx -s reload')  # nginx upstream切换

# 金丝雀：先切1%的流量
def canary_deploy():
    deploy_green()
    # 修改负载均衡权重 1:99
    # 观察10分钟
    # 全量切换或回滚
```

### 6. 结合Ansible写自定义模块

Ansible本身就是Python写的，你完全可以自定义模块：

```python
# library/my_disk.py（放在Ansible的library目录）
from ansible.module_utils.basic import AnsibleModule

def main():
    module = AnsibleModule(
        argument_spec=dict(
            path=dict(type='str', required=True)
        )
    )
    path = module.params['path']
    du = psutil.disk_usage(path)
    result = {
        "total_gb": round(du.total / 1024**3, 2),
        "used_gb": round(du.used / 1024**3, 2),
        "free_gb": round(du.free / 1024**3, 2),
        "percent": du.percent
    }
    module.exit_json(**result)

if __name__ == '__main__':
    main()
```

然后在playbook里直接使用：

```yaml
- name: 获取磁盘使用情况
  my_disk:
    path: /data
  register: disk_info

- debug:
    msg: "剩余空间 {{ disk_info.free_gb }} GB"
```

## 三、推荐的Python运维必备库清单

| 类别         | 推荐库                                | 用途                   |
| ------------ | ------------------------------------- | ---------------------- |
| 远程执行     | paramiko、fabric、ansible             | SSH批量操作            |
| 系统信息采集 | psutil、platform、subprocess          | CPU、内存、磁盘、网络  |
| 配置文件处理 | configparser、jinja2、pyyaml          | 解析/渲染配置文件      |
| 日志处理     | watchdog、re                          | 实时监控日志           |
| 监控告警     | prometheus_client、grafana api        | 暴露指标、推送告警     |
| 进程管理     | supervisor、pexpect                   | 服务启停               |
| 网络请求     | requests、urllib3、httpx              | 调用API                |
| 数据分析     | pandas、numpy                         | 批量日志分析、报表生成 |
| 容器/云平台  | docker、kubernetes、boto3、aliyun-sdk | 云原生自动化           |

## 四、写好运维脚本的几个最佳实践

1. 幂等性：脚本多次执行结果一致（学习Ansible的设计理念）
2. 日志记录：用logging模块，输出到文件+控制台
3. 异常处理：任何可能出错的地方都要try/except
4. 参数化：使用argparse或click做命令行参数
5. 配置分离：配置文件用yaml/json，敏感信息用vault或环境变量
6. 代码版本化：和业务代码一样放Git，带上README和示例
7. 测试：用pytest写单元测试，尤其是批量操作前先在测试环境跑

```python
# 示例：带日志、参数、异常处理的规范脚本框架
import argparse
import logging
from logging.handlers import RotatingFileHandler

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = RotatingFileHandler('/var/log/my_script.log', maxBytes=10*1024*1024, backupCount=5)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

def main():
    parser = argparse.ArgumentParser(description='运维自动化脚本模板')
    parser.add_argument('--dry-run', action='store_true', help='仅预览不执行')
    args = parser.parse_args()
    
    try:
        # 你的核心逻辑
        pass
    except Exception as e:
        logger.error(f"脚本执行失败: {e}", exc_info=True)
        raise

if __name__ == '__main__':
    main()
```

## 五、结语

Python早已不是“胶水语言”，而是运维工程师手中最锋利的武器。从简单的批量SSH，到复杂的自动化编排平台，几乎所有主流运维工具的底层都是Python。掌握Python运维脚本，就等于掌握了未来十年的核心竞争力。

从今天起，把每天重复敲的命令行，改写成Python脚本吧——你会发现，世界一下子安静了，也强大了。

（全文完）

如果你在实际工作中遇到具体场景需要脚本实现，欢迎留言，我可以帮你量身定制更高效的解决方案！