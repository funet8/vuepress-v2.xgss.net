# 文本处理工具：grep、awk、sed 的高级文本分析与处理

## 🔍 引言

在数据驱动的时代，文本处理是程序员、数据分析师和系统管理员的日常工作之一。日志分析、数据清洗、格式转换，甚至快速统计，都离不开高效的文本处理工具。Linux/Unix 系统中的 **grep、awk、sed** 是三大经典工具，它们轻量、强大、组合灵活，被誉为“文本三剑客”。本文将深入探讨它们在高级文本分析与处理中的应用。

------

## 🧩 工具概览

| 工具     | 主要功能                     | 典型场景                 |
| -------- | ---------------------------- | ------------------------ |
| **grep** | 模式匹配与搜索               | 日志过滤、关键字查找     |
| **awk**  | 基于列的文本处理与统计       | 数据分析、报表生成       |
| **sed**  | 流编辑器，文本替换与批量修改 | 配置文件批量替换、格式化 |

------

## 🔎 grep：高效搜索与过滤

- **基本用法**：

  ```bash
  grep "ERROR" logfile.txt
  ```

  查找日志中包含 `ERROR` 的行。

- **高级技巧**：

  - 使用正则表达式：

    ```bash
    grep -E "ERROR|WARN" logfile.txt
    ```

    同时匹配 ERROR 和 WARN。

  - 统计匹配次数：

    ```bash
    grep -c "ERROR" logfile.txt
    ```

------

## 📊 awk：文本分析与统计利器

- **基本用法**：

  ```bash
  awk '{print $1, $3}' data.txt
  ```

  输出第一列和第三列。

- **高级技巧**：

  - 条件过滤与统计：

    ```bash
    awk '$3 > 100 {count++} END {print count}' data.txt
    ```

    统计第三列大于 100 的行数。

  - 生成报表：

    ```bash
    awk -F, '{sum+=$2} END {print "平均值:", sum/NR}' data.csv
    ```

------

## ✂️ sed：批量替换与流编辑

- **基本用法**：

  ```bash
  sed 's/foo/bar/g' file.txt
  ```

  将所有 `foo` 替换为 `bar`。

- **高级技巧**：

  - 删除特定行：

    ```bash
    sed '/ERROR/d' logfile.txt
    ```

    删除包含 ERROR 的行。

  - 批量修改配置：

    ```bash
    sed -i 's/timeout=30/timeout=60/' config.ini
    ```

------

## ⚙️ 三剑客组合应用

真正的威力在于 **组合使用**：

```bash
grep "ERROR" logfile.txt | awk '{print $2}' | sed 's/:.*//'
```

- `grep` 提取包含 ERROR 的行
- `awk` 输出第二列
- `sed` 去掉冒号及其后内容

这种流水线式处理方式，可以快速完成复杂的文本分析。

------

## 🚀 总结

- **grep**：快速搜索与过滤
- **awk**：结构化分析与统计
- **sed**：灵活的文本替换与编辑

三者结合，几乎可以应对所有文本处理场景。它们不仅是系统管理员的必备工具，也是数据分析和自动化脚本中的利器。