#  OpenAI发布最新大模型GPT5、本地部署GPT开源模型



## GPT-5概述

北京时间 2025年8月8日 凌晨1点 OPENAI举行了1个小时的线上发布会，正式推出了其史上最聪明、最强大的大模型GPT-5。

GPT-5是OpenAI发布的最新一代大型语言模型，它基于Transformer架构，经过大规模的文本数据训练，能够生成流畅、自然的语言输出。与前几代相比，GPT-5的技术进步体现在其更强大的理解能力、更准确的推理能力以及更高效的对话表现。

GPT-5具备以下几个显著特点：

**更大的参数规模**：GPT-5拥有比GPT-4更多的参数，使其能够处理更为复杂的语言任务。

**多模态能力**：除了文本输入输出，GPT-5还支持图像、音频等多种数据类型的处理，能够进行跨媒体的内容生成。

**增强的推理能力**：在自然语言推理、抽象思维以及复杂问题解决方面，GPT-5表现得更为出色，能够处理更具挑战性的任务。

**更加个性化的对话**：GPT-5能够根据用户的需求提供更加个性化和具体的答案，甚至具备更灵活的情感反馈能力。

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1755001990336.png?tx)

## 如何使用GPT5

```
GPT5的中文介绍： https://openai.com/zh-Hans-CN/index/introducing-gpt-oss/
```



1. 访问ChatGPT官网，免费用户每日有次数的限额、使用钞能力。
2. 使用微软的copilot可以免登录使用GPT5、但是需要一些魔法。



## 开源模型 gpt-oss-20b 与 gpt-oss-120b

OpenAI 开源 gpt-oss-20b 与 gpt-oss-120b 两款模型，Apache 2.0 许可证，水平与 o4-mini 相当，MoE 架构，带有思维链，可微调，本地 Agent 函数调用等功能，原生 MXFP4 量化，120b可以跑在高端笔记本或者单块 H100 上，20b版本可以跑在手机上。

###  GPT-oss-120b

GPT-oss-120b 模型在核心推理基准测试中与 OpenAI o4-mini 模型几乎持平，同时能在单个 80GB GPU 上高效运行。

###  Gpt-oss-20b

Gpt-oss-20b 模型在常见基准测试中与 OpenAI o3‑mini 模型取得类似结果，且可在仅配备 16GB 内存的边缘设备上运行，使其成为设备端应用、本地推理或无需昂贵基础设施的快速迭代的理想选择。

这两个模型在工具使用、少样本函数调用、CoT推理（如在 Tau-Bench 智能体评估套件中的结果所示）以及 HealthBench 测试中表现强劲（甚至超越了 OpenAI o1 和 GPT‑4o 等专有模型）。

## gpt-oss-20b 与 gpt-oss-120b 最低硬件要求

来自ChatGPT5的回答

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1755000824661.png?tx)

来自本地gpt-oss-20b的回答

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1755000868416.png?tx)



## 如何在本地安装开源的GPT-oss-20b

星哥的测试环境

系统：Windows11专业版

CPU: 英特尔I7-13700KF

内存： 32G

硬盘：1T nvme +4T HHD

显卡：RTX 4070 Ti （12G）

## 安装最新版的 Ollama

去到ollama官网下载系统对应的软件，我这里下载window版本的。

```
 ollama 的官方下载地址。 https://ollama.com/download
```



![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1755001083912.png?tx)

再到 命令行中powershell使用 

```
ollama run gpt-oss 
ollama run gpt-oss:20b
根据不同的网络状况需要的时间不同。

PS C:\Users\Administrator> ollama list | Select-String "gpt"
gpt-oss:20b                f2b8351c629c    13 GB     5 days ago
https://ollama.com/library/gpt-oss
```

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1755001200851.png?tx)

## 在 Ollama上使用gpt-oss:20b

ollama安装完成之后，可以打开ollama界面，如图。

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1755001283509.png?tx)

## Ollama的Turbo服务

Ollama 推出了名为 “Turbo” 的付费服务，旨在解决本地运行超大模型的性能瓶颈，让用户在数据中心级的硬件上运行大型开源模型，服务月费为 20 美元。

Ollama “Turbo” 适用场景：

本地显卡显存不足，无法加载 120B 级别模型，需要快速原型验证、批量推理或高并发调用

希望保持本地环境简洁，同时获得接近数据中心的性能

据介绍，Ollama “Turbo” 服务主要解决新模型体积过大、在普通 GPU 上难以运行或运行缓慢的问题。通过将模型运行负载转移到云端，用户可以释放本地计算机（Mac, Windows, Linux）的性能。在预览阶段，Turbo 支持 gpt-oss-20b 和 gpt-oss-120b 模型。

## 最后

以上就是全部内容，GPT-5的简介和在本地搭建使用OpenAI的GPT-oss的开源模型。

写文不易，如果你都看到了这里，请点个赞和在看，分享给更多的朋友；也别忘了关注星哥玩云！这里有满满的干货分享，还有轻松有趣的技术交流～点个赞、分享给身边的小伙伴，一起成长，一起玩转技术世界吧！ 😊






