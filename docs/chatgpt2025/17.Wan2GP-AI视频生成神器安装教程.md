# 快速上手AI视频生成神器，打造你的专属创作工具



大家好，我是星哥！今天给大家带来一款真正让普通玩家也能玩转AI视频生成的神器——**Wan2GP**。这款由DeepBeepMeep开发的开源项目，通过优化显存占用技术，将原本需要80G显存的专业模型门槛降到了**6GB显存**，让RTX 10XX/20XX等老旧显卡也能流畅运行阿里Wan、腾讯Hunyuan等顶级视频生成模型。无论是自媒体创作者、设计师还是AI爱好者，都能通过本教程快速上手，免费生成高质量视频内容。



## 什么是Wan2GP

Wan2GP 是一个由DeepBeepMeep开发的开源视频生成模型项目，旨在为GPU资源有限的用户提供高质量的视频生成体验。它囊括了多种视频生成模型，包括阿里的Wan及其衍生模型、腾讯的Hunyuan Video和LTV Video等主流视频生成模型，通过简洁易用的网页界面，用户无需深入了解复杂的模型细节，即可轻松生成想要的视频内容。

Wan2GP 的问世，让广大低端显卡用户也能玩转高大上的视频生成项目了。就以HunyuanVideo 13B图生视频模型来说，原版需要至少80G显存才能跑得动的模型，现在 Wan2GP 把这个标准降低到10GB，而且生成的视频质量几乎没用任何的损失和降低。但缺点也是有的，生成时间会拉长，同时需要更大的运行内存。

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754472712474.png?tx)

## Wan2GP核心功能解析

### 突破硬件限制的黑科技

- **超低显存需求**：1.3B模型仅需6GB显存，14B模型最低10GB显存即可运行
- **老旧GPU兼容**：完美支持RTX 1060至50系全系列N卡，通过CUDA 12.8优化实现性能跃升
- **多模型集成**：整合阿里Wan2.2、腾讯HunyuanVideo、LTV Video等主流开源模型

### 全能创作工具集

- **文生视频(T2V)**：输入文本描述生成动态视频，支持中英双语提示词
- **图生视频(I2V)**：静态图片转视频，新增首尾帧生成模式，实现精准镜头控制
- **高级编辑功能**：蒙版编辑、提示词增强、时空生成、多开WebUI等专业工具
- **LoRA扩展**：支持自定义模型训练，满足个性化风格需求

## 系统环境准备

### 最低配置要求

| 组件     | 最低配置                   | 推荐配置                    |
| -------- | -------------------------- | --------------------------- |
| 操作系统 | Windows 10 64位            | Windows 11专业版            |
| 显卡     | NVIDIA GTX 1660 (6GB VRAM) | NVIDIA RTX 4070 (12GB VRAM) |
| 内存     | 16GB DDR4                  | 32GB DDR5                   |
| 存储     | 100GB SSD（剩余空间）      | 200GB NVMe SSD              |
| 其他     | CUDA 12.8+                 | 科学上网环境（模型下载）    |

星哥的测试环境

系统：Windows11专业版

CPU: 英特尔I7-13700KF

内存： 32G

硬盘：1T nvme +4T HHD

显卡：RTX 4070 Ti 

## 详细安装步骤

### 要求环境

如果安装了，请忽略

- Python 3.10.9 【**[点击下载](https://www.python.org/downloads/release/python-3109/)**】
- Git 【**[点击下载](https://git-scm.com/downloads)**】
- Conda 【**[点击下载](https://repo.anaconda.com/miniconda/Miniconda3-py311_24.5.0-0-Windows-x86_64.exe)**】

## RTX 10XX 至 RTX 40XX（稳定版）的安装

### 1.克隆项目到本地

通过 Conda 创建一个名为 wan2gp 的虚拟环境，并指定安装 Python 版本为 3.10.9

```
git clone https://github.com/deepbeepmeep/Wan2GP.git
cd Wan2GP
conda create -n wan2gp python=3.10.9
conda activate wan2gp
```



星哥遇到报错：

```
报错：
conda : 无法将“conda”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正
确，然后再试一次。
所在位置 行:1 字符: 1
+ conda create -n wan2gp python=3.10.9
+ ~~~~~
    + CategoryInfo          : ObjectNotFound: (conda:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException
	
应该如何解决？

解决：添加环境变量
$Env:Path += ";C:\Users\Administrator\miniconda3\Scripts;C:\Users\Administrator\miniconda3\condabin"
```



### 2.安装PyTorch

```
pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/test/cu124
```

![image-20250801145533229](https://imgoss.xgss.net/picgo-tx2025/image-20250801145533229.png?tx)



### 3.安装依赖项

```
pip install -r requirements.txt
```

![image-20250801155931211](H:\typora_images\image-20250801155931211.png)

### 4.可选的性能优化（自由选择）

贤者注意力（速度提高 30%）

```
pip install triton-windows
```

Sage 2 Attention（速度提高 40%）

```
pip install triton-windows 
pip install https://github.com/woct0rdho/SageAttention/releases/download/v2.1.1-windows/sageattention-2.1.1+cu126torch2.6.0-cp310-cp310-win_amd64.whl
```

**运行使用方法：**

```
python wgp.py  # 文字转视频 (default)
python wgp.py --i2v  # 图片转视频
```

运行后在CMD下可以看到UI界面的地址：http://localhost:7860

## 50XX系列显卡

如果你是英伟达50系列的显卡，可以使用以下命令部署

```
git clone https://github.com/deepbeepmeep/Wan2GP.git
cd Wan2GP
conda create -n wan2gp python=3.10.9
conda activate wan2gp
pip install torch==2.7.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/test/cu124
pip install -r requirements.txt

python wgp.py  # Text-to-video (default)
python wgp.py --i2v  # Image-to-video
```



## 注意

第一次使用模型，需要下载模型，不是浏览器卡主了

使用Wan2GP需要下载huggingface.co的模型，如果网络不好可能无法完成！



## 让其他小伙伴可以访问项目。

如果局域网中有其他的小伙伴想要访问此项目，可以把 文件“wgp.py”中的一个配置修改

把“localhost”改成“0.0.0.0”

```
wgp.py 文件中的8932行
这一行注释掉： #server_name = os.getenv("SERVER_NAME", "localhost")
把“localhost”改成“0.0.0.0”
server_name = os.getenv("SERVER_NAME", "0.0.0.0")  
        
```

![image-20250806170143197](https://imgoss.xgss.net/picgo-tx2025/image-20250806170143197.png?tx)

关闭CMD，再次运行

```
conda activate wan2gp
python wgp.py
即可显示：
```

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754460990568.png?tx)



## 文生视频、生成第一个视频

使用以下提示词，选择wan2.1  ，模型选择 Text2video 1.3B

### 提示词

日落，暖色调，中景，低饱和度，日光，侧光，晴天光。在一间厨房里，一位外国白人男子正在准备食物。平拍中近景镜头中，他穿着一件白色衬衫和黑色领带，站在一张桌子前，桌子上放着一个蓝色的杯子、一罐糖和其他一些调料瓶。他从罐子中舀出一些糖放入杯子里。虚化的背景是一面装饰有花卉图案墙纸的墙壁，上面挂着一个白色的橱柜，里面装满了各种物品。阳光透过窗户洒进室内。

### Text2video 1.3B 文生视频

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754467032314.png?tx)

会先现在模型，不要以为浏览器卡主了

生成的截图：

![image-20250806155324556](https://imgoss.xgss.net/picgo-tx2025/image-20250806155324556.png?tx)

生成的视频会在outputs里面。

生成的视频：

<video src="https://imgoss.xgss.net/picgo-tx2025/2025-08-06-video-Text2video-1.3B.mp4"></video>



对比

提示词来自：https://mp.weixin.qq.com/s/ucHuyomTZ6X2q_tL3wHQQg （晴天光）



![img](https://imgoss.xgss.net/picgo-tx2025/2025-08-06-video.gif)



## 内存溢出报错

由于GPU只有的显存只有12G，使用14B生成视频可能会报错。

Memory Management for the GPU Poor

```
* Running on local URL:  http://0.0.0.0:7860

To create a public link, set `share=True` in `launch()`.
Loading Model 'ckpts/hunyuan_video_720_quanto_int8.safetensors' ...
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
************ Memory Management for the GPU Poor (mmgp 3.5.3) by DeepBeepMeep ************
```

## 文生视频

这时候就要请出我们的坤坤出场了！

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754473122517.png?tx)

提示词： 一个男生穿着背带裤打篮球

模型：Fun InP image2video 1.3B

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754473085118.png?tx)

哎呀报错了：

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754473195734.png?tx)

要使用魔法上网

生成视频时的系统负载

![img](https://imgoss.xgss.net/picgo-tx2025/QQ_1754474369575.png?tx)

生成的视频：

不好评价啊

<video src="https://imgoss.xgss.net/picgo-tx2025/2025-08-06-dalanqiu.mp4"></video>



# 最后

通过本文的安装教程，相信你已经可以顺利搭建起属于自己的AI视频生成工具——Wan2GP。赶快动手试试吧，看看AI能为你带来什么样的创作惊喜！

写文不易，如果你都看到了这里，请点个赞和在看，分享给更多的朋友；也别忘了关注星哥玩云！这里有满满的干货分享，还有轻松有趣的技术交流～点个赞、分享给身边的小伙伴，一起成长，一起玩转技术世界吧！ 😊

